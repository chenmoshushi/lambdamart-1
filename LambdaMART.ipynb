{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "import matplotlib as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_buf1 = []\n",
    "results_buf2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dict_by_qid(qids, pred_y):\n",
    "    \"\"\"\n",
    "        Возвращает словарь, в котором по qid можно получить список индексов. \n",
    "        Каждый индекс соответствует месту элемента с этим индексом в поисковой выдаче для данного qid.\n",
    "    \"\"\"\n",
    "    # Найдём для каждого из запросов порядок поисковой выдачи\n",
    "    unique_qids = np.unique(qids)\n",
    "    id_y = defaultdict(np.array)\n",
    "    n_elems = pred_y.shape[0]\n",
    "    for qid in unique_qids:\n",
    "        # Индексы тех элементов, у которых запрос равен qid\n",
    "        ids_for_qid = np.arange(n_elems)[qids==qid]\n",
    "        # Тот же pred_y, только, у которого элементы с неравным qid будут равны 0\n",
    "        buf = np.zeros(n_elems)\n",
    "        for idx in ids_for_qid:\n",
    "            buf[idx] = pred_y[idx]\n",
    "        id_y[qid] = np.argsort(np.argsort(buf)[::-1])\n",
    "    return id_y\n",
    "\n",
    "\n",
    "def ndcgl(pred_y, y, qids, L=10):\n",
    "    \"\"\"\n",
    "        pred_y : предсказанные значения функции ранжирования\n",
    "        y : метки релевантности\n",
    "        qids : id запросов, для каждого элемента\n",
    "    \"\"\"\n",
    "    id_y = get_dict_by_qid(qids, pred_y)\n",
    "    buf = 0.\n",
    "    for qid in np.unique(qids):\n",
    "        dcgl = 0.\n",
    "        idcgl = 0.\n",
    "        # Отсортируем значения по убыванию функции ранжирования\n",
    "        #idx = np.argsort(y_pred)[::-1]\n",
    "        idx = id_y[qid]\n",
    "        # Метки релевантности для отсортированного массива y_pred\n",
    "        #l = y[idx]\n",
    "        for i in xrange(L):\n",
    "            #if qids[i] == qid:\n",
    "            # Метка релевантности для данного элемента\n",
    "            l = y[idx == i][0]\n",
    "            dcgl += (2. ** l - 1) / np.log2(i + 2)\n",
    "            idcgl += 1 / np.log2(i + 2)\n",
    "        buf += dcgl / idcgl\n",
    "    return buf / len(np.unique(qids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LambdaMART:\n",
    "    def __init__(self, n_estimators, base_estimator=DecisionTreeRegressor(), step_estimator=DecisionTreeRegressor(),\n",
    "                 alpha=1., beta=1., adaptive_step=True, feature_subset=False, feature_fraction=1., stochastic=False):\n",
    "        \"\"\"\n",
    "            n_estimators : число деревьев в обучении\n",
    "            base_estimator : выбор модели для каждой итерации\n",
    "            step_estimator : выбор модели для предсказания темпа обучения\n",
    "            alpha : коэффициент регуляризации XGBoost\n",
    "            beta : коэффициент при предсказании темпа обучения\n",
    "            adaptive_step : использовать адаптивный шаг бустинга или нет\n",
    "            feature_subset : использовать случайный набор признаков или нет\n",
    "        \"\"\"\n",
    "        self.estimators = []\n",
    "        self.step_estimators = []\n",
    "        self.feature_idx = []\n",
    "        self.n_estimators = n_estimators\n",
    "        self.base_estimator = base_estimator\n",
    "        self.step_estimator = step_estimator\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.adaptive_step = adaptive_step\n",
    "        self.feature_subset = feature_subset\n",
    "        self.feature_fraction = feature_fraction\n",
    "        self.stochastic = stochastic\n",
    "        \n",
    "    def fit(self, X_train, y_train, qids_train, queries_train, X_test, y_test, qids_test, queries_test, verbose=False):\n",
    "        \"\"\"\n",
    "            X : признаки пар запрос-документ\n",
    "            y : метки релевантности\n",
    "            qids : id запросов\n",
    "            queries : признаки запросов\n",
    "        \"\"\"\n",
    "        X = X_train\n",
    "        y = y_train\n",
    "        qids = qids_train\n",
    "        queries = queries_train\n",
    "        self.estimators = []\n",
    "        self.step_estimators = []\n",
    "        # Препроцессинг для ускорения подсчитывания градиента\n",
    "        # id_y = np.argsort(np.argsort(y_train)[::-1])\n",
    "        for i in xrange(self.n_estimators):\n",
    "            predicted = self.predict(X_train, qids_train, queries_train, verbose)\n",
    "            y_pred = self.predict(X_test, qids_test, queries_test)\n",
    "            train_result = ndcgl(predicted, y_train, qids_train)\n",
    "            test_result = ndcgl(y_pred, y_test, qids_test)\n",
    "            print \"Iteration {}, train_result {}, test_result {}\".format(i, train_result, test_result)\n",
    "            if self.feature_subset:\n",
    "                results_buf1.append((i, train_result, test_result))\n",
    "            else:\n",
    "                results_buf2.append((i, train_result, test_result))\n",
    "                #print \"Iteration \", i, \"train_result\", ndcgl(predicted) \"\" test_result \", \n",
    "            sub_idx = []\n",
    "            if self.stochastic:\n",
    "                # Выбираем подвыборку элементов\n",
    "                sub_idx = np.random.choice(np.arange(X_train.shape[0]), int(0.6 * X_train.shape[0]), replace=False)\n",
    "                #grad, h = self.loss_grad(predicted[sub_idx], y_train[sub_idx], id_y[sub_idx])\n",
    "                grad, h = self.loss_grad(predicted[sub_idx], y_train[sub_idx], qids[sub_idx])\n",
    "                X = X_train[sub_idx]\n",
    "                y = y_train[sub_idx]\n",
    "                qids = qids_train[sub_idx]\n",
    "                queries = queries_train[sub_idx]\n",
    "            else:\n",
    "                #grad, h = self.loss_grad(predicted, y, id_y)\n",
    "                grad, h = self.loss_grad(predicted, y, qids)\n",
    "            if verbose:\n",
    "                print \"Grad:\"\n",
    "                print grad\n",
    "                print \"H:\"\n",
    "                print h\n",
    "            estimator = deepcopy(self.base_estimator)\n",
    "            if self.feature_subset:\n",
    "                # Список индексов фичей\n",
    "                feature_idx = np.random.choice(np.arange(X.shape[1]), int(self.feature_fraction * X.shape[1]), replace=False)\n",
    "                self.feature_idx.append(feature_idx)\n",
    "                estimator.fit(X.T[feature_idx].T, -grad/ (self.alpha + h))\n",
    "            else:\n",
    "                estimator.fit(X, -grad/ (self.alpha + h))\n",
    "            self.estimators.append(estimator)\n",
    "            if verbose:\n",
    "                print \"Predict:\"\n",
    "                print predicted\n",
    "            # Обучим предсказатель шага\n",
    "            if self.adaptive_step:\n",
    "                step_estimator = deepcopy(self.step_estimator)\n",
    "                # Список всех запросов(уникальных)\n",
    "                qs = np.unique(qids)\n",
    "                # Список значений того, что нужно предсказывать\n",
    "                pred_values = np.zeros(len(qs))\n",
    "                q_list = np.zeros((len(qs), queries.shape[1]))\n",
    "                for idx, q in enumerate(qs):\n",
    "                    # Суммируем значения по всем элементам с данным запросом q\n",
    "                    pred_values[idx] = 0.\n",
    "                    for j in xrange(X.shape[0]):\n",
    "                        if qids[j] == q:\n",
    "                            q_list[idx] = queries[j]\n",
    "                            pred_values[idx] += 1. / (1. + self.beta * h[j])            \n",
    "                    #q_list[idx] = q_dict[q]\n",
    "                sum_pred_values = np.sum(pred_values)\n",
    "                step_estimator.fit(q_list, pred_values * len(qs) / sum_pred_values)\n",
    "                self.step_estimators.append(step_estimator)\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X, qids, queries, verbose=False):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for est_i, estimator in enumerate(self.estimators):\n",
    "            if self.feature_subset:\n",
    "                feature_idx = self.feature_idx[est_i]\n",
    "                est_result = estimator.predict(X.T[feature_idx].T)\n",
    "            else:\n",
    "                est_result = estimator.predict(X)\n",
    "            for i in xrange(X.shape[0]):\n",
    "                step = 1. / (i + 1.)\n",
    "                if self.adaptive_step:\n",
    "                    step = self.step_estimators[est_i].predict(queries[i].reshape(1,-1)[0])\n",
    "                if verbose:\n",
    "                    print \"Step: \", step, \" for qid=\", qids[i]\n",
    "                y_pred[i] += est_result[i] * step\n",
    "        return y_pred\n",
    "    \n",
    "    def loss_grad(self, pred_y, y, qids):\n",
    "        n_elems = y.shape[0]\n",
    "        grad = np.zeros(n_elems)\n",
    "        h = np.zeros(n_elems)\n",
    "        # id_y - индексы в массиве pred_y, отсортированные по убыванию ранжирующей функции \n",
    "        #id_y = np.argsort(np.argsort(y)[::-1])\n",
    "        # Найдём для каждого из запросов порядок поисковой выдачи\n",
    "        id_y = get_dict_by_qid(qids, pred_y)\n",
    "        for i in xrange(n_elems):\n",
    "            for j in xrange(n_elems):\n",
    "                if qids[i] == qids[j]:\n",
    "                    buf = 0.\n",
    "                    delta_ndcg = np.abs(self.ndcg_replace(y[i], y[j], id_y[qids[i]][i], id_y[qids[j]][j]))\n",
    "                    if y[i] > y[j]:\n",
    "                        buf = -self.rho(pred_y[i], pred_y[j])\n",
    "                    if y[i] < y[j]:\n",
    "                        buf = self.rho(pred_y[j], pred_y[i])\n",
    "                    if buf != 0.:\n",
    "                        grad[i] += delta_ndcg * buf\n",
    "                    h[i] += delta_ndcg * self.rho(pred_y[i], pred_y[j]) * (1 - self.rho(pred_y[i], pred_y[j]))\n",
    "        return grad, h\n",
    "        \n",
    "    \"\"\"def double_grad(self, pred_y, y):\n",
    "        n_elems = y.shape[0]\n",
    "        h = np.zeros(n_elems)\n",
    "        # id_y - индексы в массиве pred_y, отсортированные по убыванию ранжирующей функции \n",
    "        id_y = np.argsort(np.argsort(y)[::-1])\n",
    "        for i in xrange(n_elems):\n",
    "            for j in xrange(n_elems):\n",
    "                delta_ndcg = np.abs(self.ndcg_replace(y[i], y[j], id_y[i], id_y[j]))\n",
    "                h[i] += delta_ndcg * self.rho(pred_y[i], pred_y[j]) * (1 - self.rho(pred_y[i], pred_y[j]))\n",
    "        return h\"\"\"\n",
    "    \n",
    "    def ndcg_replace(self, value_a, value_b, id_a, id_b):\n",
    "        return (2. ** value_b - 2. ** value_a) * (1./ np.log2(2 + id_a) - 1./ np.log2(2 + id_b))\n",
    "    \n",
    "    def rho(self, a, b):\n",
    "        return 1. / (1. + np.exp(a - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем часть датасета MQ2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Проверка на части датасета MQ2007\n",
    "fin = open('train.txt', 'r')\n",
    "\n",
    "num_elems = 10000\n",
    "X = np.zeros((num_elems, 46))\n",
    "y = np.zeros(num_elems)\n",
    "queries = np.zeros(num_elems)\n",
    "\n",
    "num = 0\n",
    "i = 0\n",
    "\n",
    "lines = fin.readlines()[:num_elems]\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    parsed = line.split(' ')\n",
    "    y[i] = int(parsed[0])\n",
    "    queries[i] = int(parsed[1][4:])\n",
    "    for j in xrange(46):\n",
    "        if j < 9:\n",
    "            X[i][j] = float(parsed[j + 2][2:])\n",
    "        else:\n",
    "            X[i][j] = float(parsed[j + 2][3:])\n",
    "                \n",
    "# Нормализуем y\n",
    "y /= np.max(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем признаки для запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Признаки для запросов\n",
    "query_d = 20 # Число признаков в запросе. \n",
    "q_dict = defaultdict(lambda : np.zeros(query_d)) # dictionary, который по id запроса возвращает его признаки\n",
    "\n",
    "unique_q, counts = np.unique(queries, return_counts=True)\n",
    "for i,q in enumerate(unique_q):\n",
    "    for j in xrange(X.shape[0]):\n",
    "        if queries[j] == q:\n",
    "            q_dict[q] += X[j][11:31]/ counts[i]\n",
    "            #q_dict[q] += X[j][:40]/ counts[i]\n",
    "\n",
    "# Финальная матрица для запросов. По индексу получаем признаки запроса, соответствующие элементу из X с этим индексом\n",
    "q = np.zeros((num_elems, query_d))\n",
    "for i in xrange(num_elems):\n",
    "    q[i] = q_dict[queries[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Хорошее перемешивание\n",
    "unique_q = np.unique(queries)\n",
    "num_q = unique_q.shape[0]\n",
    "q_idx = np.random.permutation(num_q)\n",
    "Q_for_train = unique_q[q_idx][:num_q*3/4]\n",
    "Q_for_test = unique_q[q_idx][num_q*3/4:]\n",
    "\n",
    "train_idx = np.zeros(0, dtype=int32)\n",
    "test_idx = np.zeros(0, dtype=int32)\n",
    "\n",
    "for i, q_id in enumerate(queries):\n",
    "    if (Q_for_train == q_id).any():\n",
    "        train_idx = np.append(train_idx, int(i))\n",
    "    else:\n",
    "        test_idx = np.append(test_idx, int(i))\n",
    "\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "q_train = queries[train_idx]\n",
    "queries_train = q[train_idx]\n",
    "\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n",
    "q_test = queries[test_idx]\n",
    "queries_test = q[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты на 10000 элементах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.155186474972\n",
      "0.432043887205\n"
     ]
    }
   ],
   "source": [
    "clf_temp = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "print ndcgl(clf_temp.predict(X_test), y_test, q_test)\n",
    "print ndcgl(clf_temp.predict(X_train), y_train, q_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.215823730827\n",
      "0.307199993247\n"
     ]
    }
   ],
   "source": [
    "clf_temp = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "print ndcgl(clf_temp.predict(X_test), y_test, q_test)\n",
    "print ndcgl(clf_temp.predict(X_train), y_train, q_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 400\n",
    "clf2 = LambdaMART(n, alpha=0.5, beta=1., feature_subset=True, feature_fraction=0.3)\n",
    "clf1 = LambdaMART(n, alpha=0.5, beta=1.)\n",
    "results_buf1 = []\n",
    "results_buf2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, train_result 0.0783982689787, test_result 0.37424688276\n",
      "Iteration 1, train_result 0.42096213728, test_result 0.167110992641\n",
      "Iteration 2, train_result 0.445072875726, test_result 0.182851379234\n",
      "Iteration 3, train_result 0.445094466114, test_result 0.18400793999\n",
      "Iteration 4, train_result 0.445094466114, test_result 0.184792146723\n",
      "Iteration 5, train_result 0.445094466114, test_result 0.186931858531\n",
      "Iteration 6, train_result 0.445094466114, test_result 0.190313027066\n",
      "Iteration 7, train_result 0.445094466114, test_result 0.183425155313\n",
      "Iteration 8, train_result 0.445094466114, test_result 0.187854685173\n",
      "Iteration 9, train_result 0.445094466114, test_result 0.186507867096\n",
      "Iteration 10, train_result 0.443657706432, test_result 0.183089056008\n",
      "Iteration 11, train_result 0.443657706432, test_result 0.18614673592\n",
      "Iteration 12, train_result 0.443657706432, test_result 0.188247786563\n",
      "Iteration 13, train_result 0.443657706432, test_result 0.185881645544\n",
      "Iteration 14, train_result 0.443657706432, test_result 0.190768378842\n",
      "Iteration 15, train_result 0.444005361012, test_result 0.186629994319\n",
      "Iteration 16, train_result 0.444005361012, test_result 0.189765757905\n",
      "Iteration 17, train_result 0.444037112016, test_result 0.190991839463\n",
      "Iteration 18, train_result 0.444037112016, test_result 0.191255336836\n",
      "Iteration 19, train_result 0.444037112016, test_result 0.187888751061\n",
      "Iteration 20, train_result 0.444005361012, test_result 0.188211638261\n",
      "Iteration 21, train_result 0.444872215468, test_result 0.187378519487\n",
      "Iteration 22, train_result 0.445598579864, test_result 0.189768633023\n",
      "Iteration 23, train_result 0.446655933961, test_result 0.191107811884\n",
      "Iteration 24, train_result 0.446127790552, test_result 0.189375599216\n",
      "Iteration 25, train_result 0.44691824133, test_result 0.191318035456\n",
      "Iteration 26, train_result 0.446881324987, test_result 0.191346445651\n",
      "Iteration 27, train_result 0.447454405178, test_result 0.192327405008\n",
      "Iteration 28, train_result 0.449094387223, test_result 0.193437861315\n",
      "Iteration 29, train_result 0.449418014113, test_result 0.193405220677\n",
      "Iteration 30, train_result 0.450286659388, test_result 0.191816651096\n",
      "Iteration 31, train_result 0.449664904783, test_result 0.192694762989\n",
      "Iteration 32, train_result 0.451976280727, test_result 0.193115797702\n",
      "Iteration 33, train_result 0.451700093144, test_result 0.193411300828\n",
      "Iteration 34, train_result 0.45161423579, test_result 0.19316777901\n",
      "Iteration 35, train_result 0.453665517549, test_result 0.193895609044\n",
      "Iteration 36, train_result 0.454881474965, test_result 0.191968521108\n",
      "Iteration 37, train_result 0.455004435915, test_result 0.19642668982\n",
      "Iteration 38, train_result 0.455113010291, test_result 0.194905070828\n",
      "Iteration 39, train_result 0.456019485783, test_result 0.19605790155\n",
      "Iteration 40, train_result 0.456863000591, test_result 0.194414597694\n",
      "Iteration 41, train_result 0.456890510683, test_result 0.194864489463\n",
      "Iteration 42, train_result 0.45801857815, test_result 0.195050367483\n",
      "Iteration 43, train_result 0.458527594055, test_result 0.195498843726\n",
      "Iteration 44, train_result 0.459579330994, test_result 0.195488166577\n",
      "Iteration 45, train_result 0.459994082197, test_result 0.195702027528\n",
      "Iteration 46, train_result 0.458427938501, test_result 0.196232856286\n",
      "Iteration 47, train_result 0.457199099383, test_result 0.196617976894\n",
      "Iteration 48, train_result 0.457862124467, test_result 0.196739021936\n",
      "Iteration 49, train_result 0.458873295288, test_result 0.197691549889\n",
      "Iteration 50, train_result 0.458873295288, test_result 0.196965904105\n",
      "Iteration 51, train_result 0.459505482742, test_result 0.196282248911\n",
      "Iteration 52, train_result 0.459505482742, test_result 0.194879294062\n",
      "Iteration 53, train_result 0.459265554207, test_result 0.195984377765\n",
      "Iteration 54, train_result 0.459265554207, test_result 0.195751183561\n",
      "Iteration 55, train_result 0.459265554207, test_result 0.195858729243\n",
      "Iteration 56, train_result 0.459265554207, test_result 0.194794192455\n",
      "Iteration 57, train_result 0.459287044372, test_result 0.194668989986\n",
      "Iteration 58, train_result 0.459715450214, test_result 0.19423698026\n",
      "Iteration 59, train_result 0.459715450214, test_result 0.197089690199\n",
      "Iteration 60, train_result 0.459715450214, test_result 0.198530478507\n",
      "Iteration 61, train_result 0.459715450214, test_result 0.198438279003\n",
      "Iteration 62, train_result 0.459715450214, test_result 0.198331416866\n",
      "Iteration 63, train_result 0.459715450214, test_result 0.198539842981\n",
      "Iteration 64, train_result 0.459715450214, test_result 0.197942666572\n",
      "Iteration 65, train_result 0.459715450214, test_result 0.19849680711\n",
      "Iteration 66, train_result 0.459715450214, test_result 0.198211921082\n",
      "Iteration 67, train_result 0.459715450214, test_result 0.198103978851\n",
      "Iteration 68, train_result 0.459581363244, test_result 0.198358209782\n",
      "Iteration 69, train_result 0.459581363244, test_result 0.19973965446\n",
      "Iteration 70, train_result 0.459581363244, test_result 0.199171898561\n",
      "Iteration 71, train_result 0.459581363244, test_result 0.199717357624\n",
      "Iteration 72, train_result 0.459581363244, test_result 0.198800793287\n",
      "Iteration 73, train_result 0.459581363244, test_result 0.200299926319\n",
      "Iteration 74, train_result 0.459581363244, test_result 0.199606714884\n",
      "Iteration 75, train_result 0.459581363244, test_result 0.201105852209\n",
      "Iteration 76, train_result 0.459581363244, test_result 0.201053770266\n",
      "Iteration 77, train_result 0.459799535213, test_result 0.201027065713\n",
      "Iteration 78, train_result 0.459799535213, test_result 0.200640856114\n",
      "Iteration 79, train_result 0.459799535213, test_result 0.201089168958\n",
      "Iteration 80, train_result 0.459799535213, test_result 0.200671319188\n",
      "Iteration 81, train_result 0.459799535213, test_result 0.200675041274\n",
      "Iteration 82, train_result 0.459799535213, test_result 0.199675248603\n",
      "Iteration 83, train_result 0.459799535213, test_result 0.199526304743\n",
      "Iteration 84, train_result 0.459799535213, test_result 0.199535127253\n",
      "Iteration 85, train_result 0.459799535213, test_result 0.199535127253\n",
      "Iteration 86, train_result 0.459799535213, test_result 0.199500942093\n",
      "Iteration 87, train_result 0.459799535213, test_result 0.199120999569\n",
      "Iteration 88, train_result 0.459415023536, test_result 0.198654804683\n",
      "Iteration 89, train_result 0.459415023536, test_result 0.198970276712\n",
      "Iteration 90, train_result 0.459415023536, test_result 0.198934749649\n",
      "Iteration 91, train_result 0.459415023536, test_result 0.199009140732\n",
      "Iteration 92, train_result 0.459415023536, test_result 0.198997980887\n",
      "Iteration 93, train_result 0.459415023536, test_result 0.198782042788\n",
      "Iteration 94, train_result 0.459415023536, test_result 0.19901586293\n",
      "Iteration 95, train_result 0.459415023536, test_result 0.199032166047\n",
      "Iteration 96, train_result 0.458837166874, test_result 0.198582274278\n",
      "Iteration 97, train_result 0.458837166874, test_result 0.198548089118\n",
      "Iteration 98, train_result 0.458837166874, test_result 0.198997980887\n",
      "Iteration 99, train_result 0.458837166874, test_result 0.198592675714\n",
      "Iteration 100, train_result 0.458837166874, test_result 0.198133961434\n",
      "Iteration 101, train_result 0.459583723488, test_result 0.198142783945\n",
      "Iteration 102, train_result 0.45961123358, test_result 0.198142783945\n",
      "Iteration 103, train_result 0.45961123358, test_result 0.198142783945\n",
      "Iteration 104, train_result 0.459638743672, test_result 0.198549504644\n",
      "Iteration 105, train_result 0.459638743672, test_result 0.198262251367\n",
      "Iteration 106, train_result 0.459638743672, test_result 0.198151680077\n",
      "Iteration 107, train_result 0.459878672207, test_result 0.197437121617\n",
      "Iteration 108, train_result 0.459878672207, test_result 0.198505374385\n",
      "Iteration 109, train_result 0.459878672207, test_result 0.198229962099\n",
      "Iteration 110, train_result 0.459878672207, test_result 0.198229962099\n",
      "Iteration 111, train_result 0.459878672207, test_result 0.198271554244\n",
      "Iteration 112, train_result 0.459878672207, test_result 0.197862101729\n",
      "Iteration 113, train_result 0.459878672207, test_result 0.198063879871\n",
      "Iteration 114, train_result 0.460396641411, test_result 0.197779571453\n",
      "Iteration 115, train_result 0.460562476303, test_result 0.198609729665\n",
      "Iteration 116, train_result 0.460562476303, test_result 0.199069780405\n",
      "Iteration 117, train_result 0.460562476303, test_result 0.198572275727\n",
      "Iteration 118, train_result 0.459392619941, test_result 0.198616372589\n",
      "Iteration 119, train_result 0.459392619941, test_result 0.198486191962\n",
      "Iteration 120, train_result 0.459392619941, test_result 0.1987160527\n",
      "Iteration 121, train_result 0.459392619941, test_result 0.198707156567\n",
      "Iteration 122, train_result 0.459917892209, test_result 0.198486191962\n",
      "Iteration 123, train_result 0.459917892209, test_result 0.198031168686\n",
      "Iteration 124, train_result 0.459917892209, test_result 0.198075755282\n",
      "Iteration 125, train_result 0.460081654442, test_result 0.19800959564\n",
      "Iteration 126, train_result 0.460081654442, test_result 0.198463178413\n",
      "Iteration 127, train_result 0.460081654442, test_result 0.19759915896\n",
      "Iteration 128, train_result 0.460081654442, test_result 0.19759915896\n",
      "Iteration 129, train_result 0.460299826411, test_result 0.197651226162\n",
      "Iteration 130, train_result 0.460299826411, test_result 0.197219216436\n",
      "Iteration 131, train_result 0.460299826411, test_result 0.19759915896\n",
      "Iteration 132, train_result 0.460299826411, test_result 0.197201334393\n",
      "Iteration 133, train_result 0.460299826411, test_result 0.197167149233\n",
      "Iteration 134, train_result 0.460299826411, test_result 0.197201334393\n",
      "Iteration 135, train_result 0.460299826411, test_result 0.197201334393\n",
      "Iteration 136, train_result 0.460299826411, test_result 0.197219216436\n",
      "Iteration 137, train_result 0.460299826411, test_result 0.19805787324\n",
      "Iteration 138, train_result 0.460299826411, test_result 0.198083235889\n",
      "Iteration 139, train_result 0.460299826411, test_result 0.19912619963\n",
      "Iteration 140, train_result 0.460299826411, test_result 0.199135022141\n",
      "Iteration 141, train_result 0.460299826411, test_result 0.199108317587\n",
      "Iteration 142, train_result 0.460299826411, test_result 0.199108317587\n",
      "Iteration 143, train_result 0.460299826411, test_result 0.199108317587\n",
      "Iteration 144, train_result 0.460299826411, test_result 0.199108317587\n",
      "Iteration 145, train_result 0.460299826411, test_result 0.199100836981\n",
      "Iteration 146, train_result 0.460299826411, test_result 0.19917819321\n",
      "Iteration 147, train_result 0.460299826411, test_result 0.198711998324\n",
      "Iteration 148, train_result 0.460299826411, test_result 0.198746183484\n",
      "Iteration 149, train_result 0.460299826411, test_result 0.198335746804\n",
      "Iteration 150, train_result 0.460299826411, test_result 0.198708417542\n",
      "Iteration 151, train_result 0.460299826411, test_result 0.199199766257\n",
      "Iteration 152, train_result 0.460299826411, test_result 0.199199766257\n",
      "Iteration 153, train_result 0.460299826411, test_result 0.198156802516\n",
      "Iteration 154, train_result 0.459820708019, test_result 0.198156802516\n",
      "Iteration 155, train_result 0.459820708019, test_result 0.198156802516\n",
      "Iteration 156, train_result 0.459820708019, test_result 0.197961126938\n",
      "Iteration 157, train_result 0.459820708019, test_result 0.197961126938\n",
      "Iteration 158, train_result 0.459820708019, test_result 0.197917955868\n",
      "Iteration 159, train_result 0.459820708019, test_result 0.197917955868\n",
      "Iteration 160, train_result 0.459820708019, test_result 0.197477123631\n",
      "Iteration 161, train_result 0.459820708019, test_result 0.197485946142\n",
      "Iteration 162, train_result 0.459820708019, test_result 0.197874948198\n",
      "Iteration 163, train_result 0.459820708019, test_result 0.197891251315\n",
      "Iteration 164, train_result 0.459820708019, test_result 0.197902866283\n",
      "Iteration 165, train_result 0.459820708019, test_result 0.197954933485\n",
      "Iteration 166, train_result 0.459820708019, test_result 0.198580044778\n",
      "Iteration 167, train_result 0.459820708019, test_result 0.199029936547\n",
      "Iteration 168, train_result 0.459820708019, test_result 0.199029936547\n",
      "Iteration 169, train_result 0.459820708019, test_result 0.197986972806\n",
      "Iteration 170, train_result 0.459820708019, test_result 0.19779387124\n",
      "Iteration 171, train_result 0.459820708019, test_result 0.19779387124\n",
      "Iteration 172, train_result 0.459820708019, test_result 0.197710494247\n",
      "Iteration 173, train_result 0.459820708019, test_result 0.197710494247\n",
      "Iteration 174, train_result 0.459820708019, test_result 0.197296366563\n",
      "Iteration 175, train_result 0.459820708019, test_result 0.197250566435\n",
      "Iteration 176, train_result 0.459820708019, test_result 0.197316061386\n",
      "Iteration 177, train_result 0.459820708019, test_result 0.196884051659\n",
      "Iteration 178, train_result 0.459820708019, test_result 0.196948522154\n",
      "Iteration 179, train_result 0.459820708019, test_result 0.196802003341\n",
      "Iteration 180, train_result 0.459820708019, test_result 0.195801953967\n",
      "Iteration 181, train_result 0.459820708019, test_result 0.195801953967\n",
      "Iteration 182, train_result 0.459820708019, test_result 0.197020137231\n",
      "Iteration 183, train_result 0.459820708019, test_result 0.197020137231\n",
      "Iteration 184, train_result 0.459820708019, test_result 0.197020137231\n",
      "Iteration 185, train_result 0.459820708019, test_result 0.197038019274\n",
      "Iteration 186, train_result 0.459820708019, test_result 0.198080983015\n",
      "Iteration 187, train_result 0.459820708019, test_result 0.198144665185\n",
      "Iteration 188, train_result 0.459820708019, test_result 0.197083819402\n",
      "Iteration 189, train_result 0.459820708019, test_result 0.197499526011\n",
      "Iteration 190, train_result 0.459820708019, test_result 0.197515829128\n",
      "Iteration 191, train_result 0.459820708019, test_result 0.197481643968\n",
      "Iteration 192, train_result 0.459820708019, test_result 0.197481643968\n",
      "Iteration 193, train_result 0.459820708019, test_result 0.197508348522\n",
      "Iteration 194, train_result 0.459820708019, test_result 0.197508348522\n",
      "Iteration 195, train_result 0.459820708019, test_result 0.197490466479\n",
      "Iteration 196, train_result 0.459820708019, test_result 0.197490466479\n",
      "Iteration 197, train_result 0.459820708019, test_result 0.197567366372\n",
      "Iteration 198, train_result 0.459820708019, test_result 0.197594070925\n",
      "Iteration 199, train_result 0.459820708019, test_result 0.197594070925\n",
      "Wall time: 4h 52min 24s\n"
     ]
    }
   ],
   "source": [
    "%time clf2 = clf2.fit(X_train, y_train, q_train, queries_train, X_test, y_test, q_test, queries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, train_result 0.0575187075567, test_result 0.0\n",
      "Iteration 1, train_result 0.412304768093, test_result 0.145115627204\n",
      "Iteration 2, train_result 0.421008818461, test_result 0.156843561133\n",
      "Iteration 3, train_result 0.42136294864, test_result 0.150048394382\n",
      "Iteration 4, train_result 0.421471283526, test_result 0.151543081687\n",
      "Iteration 5, train_result 0.421471283526, test_result 0.160954537966\n",
      "Iteration 6, train_result 0.421305227069, test_result 0.15883096458\n",
      "Iteration 7, train_result 0.421305227069, test_result 0.163381553307\n",
      "Iteration 8, train_result 0.421305227069, test_result 0.165640210481\n",
      "Iteration 9, train_result 0.421305227069, test_result 0.170145311329\n",
      "Iteration 10, train_result 0.421305227069, test_result 0.17263287084\n",
      "Iteration 11, train_result 0.421305227069, test_result 0.170039048498\n",
      "Iteration 12, train_result 0.421471283526, test_result 0.171257269129\n",
      "Iteration 13, train_result 0.421471283526, test_result 0.172916894992\n",
      "Iteration 14, train_result 0.421628438464, test_result 0.171395186487\n",
      "Iteration 15, train_result 0.421628438464, test_result 0.171284789325\n",
      "Iteration 16, train_result 0.421674368333, test_result 0.171557195416\n",
      "Iteration 17, train_result 0.421674368333, test_result 0.169009752173\n",
      "Iteration 18, train_result 0.421674368333, test_result 0.168736042709\n",
      "Iteration 19, train_result 0.421674368333, test_result 0.167803444581\n",
      "Iteration 20, train_result 0.421674368333, test_result 0.168922649006\n",
      "Iteration 21, train_result 0.421674368333, test_result 0.169629952627\n",
      "Iteration 22, train_result 0.421674368333, test_result 0.169751338693\n",
      "Iteration 23, train_result 0.421517213394, test_result 0.1697949066\n",
      "Iteration 24, train_result 0.421517213394, test_result 0.170836977949\n",
      "Iteration 25, train_result 0.421517213394, test_result 0.170650539622\n",
      "Iteration 26, train_result 0.421517213394, test_result 0.171647297823\n",
      "Iteration 27, train_result 0.421694664904, test_result 0.171367483981\n",
      "Iteration 28, train_result 0.421694664904, test_result 0.170797786023\n",
      "Iteration 29, train_result 0.421694664904, test_result 0.170781945603\n",
      "Iteration 30, train_result 0.421694664904, test_result 0.172046275944\n",
      "Iteration 31, train_result 0.421694664904, test_result 0.172828476142\n",
      "Iteration 32, train_result 0.421838668146, test_result 0.173010902307\n",
      "Iteration 33, train_result 0.421661216636, test_result 0.172637500512\n",
      "Iteration 34, train_result 0.421661216636, test_result 0.171903081574\n",
      "Iteration 35, train_result 0.422370916154, test_result 0.171553644967\n",
      "Iteration 36, train_result 0.422206678677, test_result 0.171961233553\n",
      "Iteration 37, train_result 0.422206678677, test_result 0.171864501284\n",
      "Iteration 38, train_result 0.422294315454, test_result 0.17073228193\n",
      "Iteration 39, train_result 0.422500185369, test_result 0.172274063017\n",
      "Iteration 40, train_result 0.42298629082, test_result 0.172680100399\n",
      "Iteration 41, train_result 0.42298629082, test_result 0.173050006881\n",
      "Iteration 42, train_result 0.42298629082, test_result 0.173417245445\n",
      "Iteration 43, train_result 0.422606885236, test_result 0.172649540844\n",
      "Iteration 44, train_result 0.422456921313, test_result 0.172233545384\n",
      "Iteration 45, train_result 0.422804575893, test_result 0.172805090885\n",
      "Iteration 46, train_result 0.422889577333, test_result 0.172909194209\n",
      "Iteration 47, train_result 0.422889577333, test_result 0.172827396141\n",
      "Iteration 48, train_result 0.423199637031, test_result 0.172729528811\n",
      "Iteration 49, train_result 0.423199637031, test_result 0.173487001638\n",
      "Iteration 50, train_result 0.423199637031, test_result 0.173114493143\n",
      "Iteration 51, train_result 0.423199637031, test_result 0.172670008594\n",
      "Iteration 52, train_result 0.423055633789, test_result 0.172166569295\n",
      "Iteration 53, train_result 0.423055633789, test_result 0.172139864742\n",
      "Iteration 54, train_result 0.423055633789, test_result 0.172148687252\n",
      "Iteration 55, train_result 0.423055633789, test_result 0.172464243947\n",
      "Iteration 56, train_result 0.423055633789, test_result 0.172138924061\n",
      "Iteration 57, train_result 0.423055633789, test_result 0.172590628611\n",
      "Iteration 58, train_result 0.423055633789, test_result 0.171726609158\n",
      "Iteration 59, train_result 0.423070900498, test_result 0.172436306432\n",
      "Iteration 60, train_result 0.423070900498, test_result 0.172362666183\n",
      "Iteration 61, train_result 0.423070900498, test_result 0.172748875781\n",
      "Iteration 62, train_result 0.423385210376, test_result 0.173180885508\n",
      "Iteration 63, train_result 0.423385210376, test_result 0.173199555875\n",
      "Iteration 64, train_result 0.423743763487, test_result 0.173165370715\n",
      "Iteration 65, train_result 0.423743763487, test_result 0.173293824047\n",
      "Iteration 66, train_result 0.423743763487, test_result 0.17214725586\n",
      "Iteration 67, train_result 0.423743763487, test_result 0.172547955796\n",
      "Iteration 68, train_result 0.423936481706, test_result 0.17296992948\n",
      "Iteration 69, train_result 0.423936481706, test_result 0.172647402051\n",
      "Iteration 70, train_result 0.423936481706, test_result 0.172536830762\n",
      "Iteration 71, train_result 0.423599760245, test_result 0.172999349384\n",
      "Iteration 72, train_result 0.423995170453, test_result 0.17353927419\n",
      "Iteration 73, train_result 0.423995170453, test_result 0.173955992685\n",
      "Iteration 74, train_result 0.423995170453, test_result 0.173955992685\n",
      "Iteration 75, train_result 0.424244255138, test_result 0.173955992685\n",
      "Iteration 76, train_result 0.424244255138, test_result 0.174255272709\n",
      "Iteration 77, train_result 0.424035665949, test_result 0.173832085493\n",
      "Iteration 78, train_result 0.424035665949, test_result 0.173938775334\n",
      "Iteration 79, train_result 0.424035665949, test_result 0.17391207078\n",
      "Iteration 80, train_result 0.424035665949, test_result 0.173431670116\n",
      "Iteration 81, train_result 0.424035665949, test_result 0.17254976862\n",
      "Iteration 82, train_result 0.424500928887, test_result 0.172681762028\n",
      "Iteration 83, train_result 0.424715478756, test_result 0.173220461595\n",
      "Iteration 84, train_result 0.424715478756, test_result 0.172661642861\n",
      "Iteration 85, train_result 0.425129548642, test_result 0.17304785246\n",
      "Iteration 86, train_result 0.425129548642, test_result 0.174407209706\n",
      "Iteration 87, train_result 0.425164083457, test_result 0.173088522131\n",
      "Iteration 88, train_result 0.425413168142, test_result 0.17380735702\n",
      "Iteration 89, train_result 0.425098858264, test_result 0.172529687619\n",
      "Iteration 90, train_result 0.425098858264, test_result 0.172575487747\n",
      "Iteration 91, train_result 0.425098858264, test_result 0.172575487747\n",
      "Iteration 92, train_result 0.425098858264, test_result 0.172640982698\n",
      "Iteration 93, train_result 0.425264914721, test_result 0.172575487747\n",
      "Iteration 94, train_result 0.425264914721, test_result 0.172727727482\n",
      "Iteration 95, train_result 0.425098858264, test_result 0.172003944785\n",
      "Iteration 96, train_result 0.425098858264, test_result 0.171306547256\n",
      "Iteration 97, train_result 0.425313408134, test_result 0.171306547256\n",
      "Iteration 98, train_result 0.425692943204, test_result 0.170217783388\n",
      "Iteration 99, train_result 0.425692943204, test_result 0.170273541594\n",
      "Iteration 100, train_result 0.425692943204, test_result 0.170239356435\n",
      "Iteration 101, train_result 0.425378633326, test_result 0.170273541594\n",
      "Iteration 102, train_result 0.425378633326, test_result 0.170462169289\n",
      "Iteration 103, train_result 0.425400464977, test_result 0.170462169289\n",
      "Iteration 104, train_result 0.425590398088, test_result 0.170462169289\n",
      "Iteration 105, train_result 0.425590398088, test_result 0.170462169289\n",
      "Iteration 106, train_result 0.425117944134, test_result 0.170488873842\n",
      "Iteration 107, train_result 0.425134036667, test_result 0.170463584815\n",
      "Iteration 108, train_result 0.425134036667, test_result 0.170463584815\n",
      "Iteration 109, train_result 0.425134036667, test_result 0.170352289736\n",
      "Iteration 110, train_result 0.42481972679, test_result 0.170390609257\n",
      "Iteration 111, train_result 0.424653670334, test_result 0.170356424097\n",
      "Iteration 112, train_result 0.424862259522, test_result 0.170095253568\n",
      "Iteration 113, train_result 0.424862259522, test_result 0.170113135611\n",
      "Iteration 114, train_result 0.424862259522, test_result 0.170532518484\n",
      "Iteration 115, train_result 0.425019414461, test_result 0.170532518484\n",
      "Iteration 116, train_result 0.425019414461, test_result 0.170489320369\n",
      "Iteration 117, train_result 0.424396996584, test_result 0.169822608148\n",
      "Iteration 118, train_result 0.424207063473, test_result 0.169822608148\n",
      "Iteration 119, train_result 0.424207063473, test_result 0.169822608148\n",
      "Iteration 120, train_result 0.424272288666, test_result 0.169822608148\n",
      "Iteration 121, train_result 0.424272288666, test_result 0.169788422988\n",
      "Iteration 122, train_result 0.424272288666, test_result 0.169891474719\n",
      "Iteration 123, train_result 0.424272288666, test_result 0.170049593517\n",
      "Iteration 124, train_result 0.424057738797, test_result 0.169891474719\n",
      "Iteration 125, train_result 0.424057738797, test_result 0.170049593517\n",
      "Iteration 126, train_result 0.424250457016, test_result 0.170115088468\n",
      "Iteration 127, train_result 0.424250457016, test_result 0.170675991668\n",
      "Iteration 128, train_result 0.424250457016, test_result 0.170675991668\n",
      "Iteration 129, train_result 0.424235190306, test_result 0.171286945683\n",
      "Iteration 130, train_result 0.424235190306, test_result 0.171286945683\n",
      "Iteration 131, train_result 0.424235190306, test_result 0.171482621261\n",
      "Iteration 132, train_result 0.424235190306, test_result 0.170837053913\n",
      "Iteration 133, train_result 0.424235190306, test_result 0.171486312265\n",
      "Iteration 134, train_result 0.424235190306, test_result 0.171936204034\n",
      "Iteration 135, train_result 0.424235190306, test_result 0.171936204034\n",
      "Iteration 136, train_result 0.424211022079, test_result 0.171936204034\n",
      "Iteration 137, train_result 0.424042472087, test_result 0.172001698985\n",
      "Iteration 138, train_result 0.424042472087, test_result 0.172467893872\n",
      "Iteration 139, train_result 0.424042472087, test_result 0.173238571393\n",
      "Iteration 140, train_result 0.424042472087, test_result 0.173692154166\n",
      "Iteration 141, train_result 0.424042472087, test_result 0.174075818776\n",
      "Iteration 142, train_result 0.424042472087, test_result 0.173661691092\n",
      "Iteration 143, train_result 0.424235190306, test_result 0.173636328443\n",
      "Iteration 144, train_result 0.424392345245, test_result 0.173654210485\n",
      "Iteration 145, train_result 0.424392345245, test_result 0.173654210485\n",
      "Iteration 146, train_result 0.424392345245, test_result 0.173654210485\n",
      "Iteration 147, train_result 0.424542309168, test_result 0.173654210485\n",
      "Iteration 148, train_result 0.424327120052, test_result 0.173654210485\n",
      "Iteration 149, train_result 0.424319929037, test_result 0.17424433901\n",
      "Iteration 150, train_result 0.42446989296, test_result 0.17424433901\n",
      "Iteration 151, train_result 0.42446989296, test_result 0.174672767956\n",
      "Iteration 152, train_result 0.42446989296, test_result 0.174672767956\n",
      "Iteration 153, train_result 0.424319929037, test_result 0.174699472509\n",
      "Iteration 154, train_result 0.424319929037, test_result 0.174699472509\n",
      "Iteration 155, train_result 0.424319929037, test_result 0.174763154679\n",
      "Iteration 156, train_result 0.424319929037, test_result 0.174763154679\n",
      "Iteration 157, train_result 0.424319929037, test_result 0.174763154679\n",
      "Iteration 158, train_result 0.424319929037, test_result 0.174763154679\n",
      "Iteration 159, train_result 0.424319929037, test_result 0.174763154679\n",
      "Iteration 160, train_result 0.424319929037, test_result 0.174763154679\n",
      "Iteration 161, train_result 0.42446989296, test_result 0.174763154679\n",
      "Iteration 162, train_result 0.424319929037, test_result 0.17465258339\n",
      "Iteration 163, train_result 0.42446989296, test_result 0.174763154679\n",
      "Iteration 164, train_result 0.42446989296, test_result 0.175084593116\n",
      "Iteration 165, train_result 0.424155583082, test_result 0.175057888563\n",
      "Iteration 166, train_result 0.424155583082, test_result 0.174975358286\n",
      "Iteration 167, train_result 0.424155583082, test_result 0.174975358286\n",
      "Iteration 168, train_result 0.424155583082, test_result 0.174953785239\n",
      "Iteration 169, train_result 0.424897033604, test_result 0.174964765838\n",
      "Iteration 170, train_result 0.424897033604, test_result 0.174925631886\n",
      "Iteration 171, train_result 0.424897033604, test_result 0.174860860724\n",
      "Iteration 172, train_result 0.424897033604, test_result 0.174860860724\n",
      "Iteration 173, train_result 0.424897033604, test_result 0.174860860724\n",
      "Iteration 174, train_result 0.424897033604, test_result 0.174860860724\n",
      "Iteration 175, train_result 0.424897033604, test_result 0.174906660852\n",
      "Iteration 176, train_result 0.424897033604, test_result 0.174906660852\n",
      "Iteration 177, train_result 0.424897033604, test_result 0.174906660852\n",
      "Iteration 178, train_result 0.424897033604, test_result 0.174906660852\n",
      "Iteration 179, train_result 0.424897033604, test_result 0.174885087805\n",
      "Iteration 180, train_result 0.424897033604, test_result 0.174474651125\n",
      "Iteration 181, train_result 0.424897033604, test_result 0.174474651125\n",
      "Iteration 182, train_result 0.424897033604, test_result 0.174526718328\n",
      "Iteration 183, train_result 0.424897033604, test_result 0.174526718328\n",
      "Iteration 184, train_result 0.424897033604, test_result 0.174461223377\n",
      "Iteration 185, train_result 0.424897033604, test_result 0.174461223377\n",
      "Iteration 186, train_result 0.424897033604, test_result 0.174526718328\n",
      "Iteration 187, train_result 0.424897033604, test_result 0.174526718328\n",
      "Iteration 188, train_result 0.424897033604, test_result 0.174500013775\n",
      "Iteration 189, train_result 0.424897033604, test_result 0.174565508726\n",
      "Iteration 190, train_result 0.424704315385, test_result 0.174565508726\n",
      "Iteration 191, train_result 0.424720407918, test_result 0.174565508726\n",
      "Iteration 192, train_result 0.424720407918, test_result 0.174565508726\n",
      "Iteration 193, train_result 0.424720407918, test_result 0.174565508726\n",
      "Iteration 194, train_result 0.424720407918, test_result 0.174565508726\n",
      "Iteration 195, train_result 0.424720407918, test_result 0.174703298332\n",
      "Iteration 196, train_result 0.424720407918, test_result 0.174869642568\n",
      "Iteration 197, train_result 0.424720407918, test_result 0.174835457408\n",
      "Iteration 198, train_result 0.424720407918, test_result 0.174835457408\n",
      "Iteration 199, train_result 0.424720407918, test_result 0.174835457408\n",
      "Iteration 200, train_result 0.424720407918, test_result 0.174835457408\n",
      "Iteration 201, train_result 0.424720407918, test_result 0.174835457408\n",
      "Iteration 202, train_result 0.424720407918, test_result 0.175387035883\n",
      "Iteration 203, train_result 0.424720407918, test_result 0.17546956616\n",
      "Iteration 204, train_result 0.424720407918, test_result 0.17546956616\n",
      "Iteration 205, train_result 0.424720407918, test_result 0.17546956616\n",
      "Iteration 206, train_result 0.42488895791, test_result 0.175423766032\n",
      "Iteration 207, train_result 0.42488895791, test_result 0.175423766032\n",
      "Iteration 208, train_result 0.42488895791, test_result 0.175423766032\n",
      "Iteration 209, train_result 0.42488895791, test_result 0.174991756306\n",
      "Iteration 210, train_result 0.424913126137, test_result 0.174991756306\n",
      "Iteration 211, train_result 0.424913126137, test_result 0.174891411503\n",
      "Iteration 212, train_result 0.424913126137, test_result 0.174925596663\n",
      "Iteration 213, train_result 0.424913126137, test_result 0.174925596663\n",
      "Iteration 214, train_result 0.424913126137, test_result 0.174925596663\n",
      "Iteration 215, train_result 0.424913126137, test_result 0.174925596663\n",
      "Iteration 216, train_result 0.424913126137, test_result 0.174904023616\n",
      "Iteration 217, train_result 0.424913126137, test_result 0.174904023616\n",
      "Iteration 218, train_result 0.424913126137, test_result 0.174904023616\n",
      "Iteration 219, train_result 0.424913126137, test_result 0.174904023616\n",
      "Iteration 220, train_result 0.424913126137, test_result 0.174904023616\n",
      "Iteration 221, train_result 0.424913126137, test_result 0.174904023616\n",
      "Iteration 222, train_result 0.424913126137, test_result 0.174904023616\n",
      "Iteration 223, train_result 0.424913126137, test_result 0.174904023616\n",
      "Iteration 224, train_result 0.424913126137, test_result 0.174882450569\n",
      "Iteration 225, train_result 0.424664041452, test_result 0.17484826541\n",
      "Iteration 226, train_result 0.424763801461, test_result 0.174882450569\n",
      "Iteration 227, train_result 0.424763801461, test_result 0.174416255683\n",
      "Iteration 228, train_result 0.424763801461, test_result 0.173984245956\n",
      "Iteration 229, train_result 0.424763801461, test_result 0.173984245956\n",
      "Iteration 230, train_result 0.424763801461, test_result 0.173984245956\n",
      "Iteration 231, train_result 0.424763801461, test_result 0.173984245956\n",
      "Iteration 232, train_result 0.424571083242, test_result 0.174045135669\n",
      "Iteration 233, train_result 0.424571083242, test_result 0.174090935797\n",
      "Iteration 234, train_result 0.424571083242, test_result 0.17345327723\n",
      "Iteration 235, train_result 0.424571083242, test_result 0.173021267503\n",
      "Iteration 236, train_result 0.424571083242, test_result 0.173021267503\n",
      "Iteration 237, train_result 0.424571083242, test_result 0.173021267503\n",
      "Iteration 238, train_result 0.424571083242, test_result 0.173086762454\n",
      "Iteration 239, train_result 0.424571083242, test_result 0.173086762454\n",
      "Iteration 240, train_result 0.424571083242, test_result 0.173086762454\n",
      "Iteration 241, train_result 0.424571083242, test_result 0.173086762454\n",
      "Iteration 242, train_result 0.424571083242, test_result 0.173142520661\n",
      "Iteration 243, train_result 0.424571083242, test_result 0.173142520661\n",
      "Iteration 244, train_result 0.424571083242, test_result 0.173142520661\n",
      "Iteration 245, train_result 0.424571083242, test_result 0.172710510934\n",
      "Iteration 246, train_result 0.424571083242, test_result 0.172710510934\n",
      "Iteration 247, train_result 0.425314492857, test_result 0.172710510934\n",
      "Iteration 248, train_result 0.425321683873, test_result 0.172710510934\n",
      "Iteration 249, train_result 0.425321683873, test_result 0.172710510934\n",
      "Iteration 250, train_result 0.425321683873, test_result 0.172710510934\n",
      "Iteration 251, train_result 0.425321683873, test_result 0.172710510934\n",
      "Iteration 252, train_result 0.425321683873, test_result 0.172710510934\n",
      "Iteration 253, train_result 0.425321683873, test_result 0.172710510934\n",
      "Iteration 254, train_result 0.425471647796, test_result 0.172710510934\n",
      "Iteration 255, train_result 0.425471647796, test_result 0.172775282096\n",
      "Iteration 256, train_result 0.425471647796, test_result 0.172741096936\n",
      "Iteration 257, train_result 0.42530559134, test_result 0.172741096936\n",
      "Iteration 258, train_result 0.42530559134, test_result 0.173173106663\n",
      "Iteration 259, train_result 0.42530559134, test_result 0.173138921503\n",
      "Iteration 260, train_result 0.42530559134, test_result 0.173173106663\n",
      "Iteration 261, train_result 0.42530559134, test_result 0.173061811584\n",
      "Iteration 262, train_result 0.425083850455, test_result 0.173061811584\n",
      "Iteration 263, train_result 0.424342399934, test_result 0.172996316633\n",
      "Iteration 264, train_result 0.424342399934, test_result 0.17307884691\n",
      "Iteration 265, train_result 0.424342399934, test_result 0.17307884691\n",
      "Iteration 266, train_result 0.424342399934, test_result 0.173494125346\n",
      "Iteration 267, train_result 0.42440698588, test_result 0.173528310506\n",
      "Iteration 268, train_result 0.424564140819, test_result 0.173580392448\n",
      "Iteration 269, train_result 0.424579407528, test_result 0.173580392448\n",
      "Iteration 270, train_result 0.424579407528, test_result 0.173580392448\n",
      "Iteration 271, train_result 0.424579407528, test_result 0.173580392448\n",
      "Iteration 272, train_result 0.424579407528, test_result 0.173028813973\n",
      "Iteration 273, train_result 0.424579407528, test_result 0.173105200102\n",
      "Iteration 274, train_result 0.424514182335, test_result 0.172682012886\n",
      "Iteration 275, train_result 0.424514182335, test_result 0.173092449566\n",
      "Iteration 276, train_result 0.424514182335, test_result 0.173092449566\n",
      "Iteration 277, train_result 0.424514182335, test_result 0.173092449566\n",
      "Iteration 278, train_result 0.424514182335, test_result 0.173058264406\n",
      "Iteration 279, train_result 0.424514182335, test_result 0.173076146449\n",
      "Iteration 280, train_result 0.424514182335, test_result 0.173326269707\n",
      "Iteration 281, train_result 0.424514182335, test_result 0.173758279434\n",
      "Iteration 282, train_result 0.424514182335, test_result 0.173758279434\n",
      "Iteration 283, train_result 0.424514182335, test_result 0.173758279434\n",
      "Iteration 284, train_result 0.424514182335, test_result 0.173758279434\n",
      "Iteration 285, train_result 0.424514182335, test_result 0.173758279434\n",
      "Iteration 286, train_result 0.424514182335, test_result 0.173758279434\n",
      "Iteration 287, train_result 0.424571577266, test_result 0.173758279434\n",
      "Iteration 288, train_result 0.424571577266, test_result 0.173758279434\n",
      "Iteration 289, train_result 0.424571577266, test_result 0.173779852481\n",
      "Iteration 290, train_result 0.424571577266, test_result 0.173779852481\n",
      "Iteration 291, train_result 0.424571577266, test_result 0.173779852481\n",
      "Iteration 292, train_result 0.424571577266, test_result 0.173228274005\n",
      "Iteration 293, train_result 0.424571577266, test_result 0.173228274005\n",
      "Iteration 294, train_result 0.424606112081, test_result 0.173228274005\n",
      "Iteration 295, train_result 0.424606112081, test_result 0.173228274005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e53b92d3b74c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time clf1 = clf1.fit(X_train, y_train, q_train, queries_train, X_test, y_test, q_test, queries_test)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Kirill\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kirill\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kirill\\Anaconda2\\lib\\site-packages\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kirill\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0dde548ff640>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, qids_train, queries_train, X_test, y_test, qids_test, queries_test, verbose)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqids_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqids_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mtrain_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndcgl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqids_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mtest_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndcgl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqids_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0dde548ff640>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, qids, queries, verbose)\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                     \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_estimators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mest_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Step: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" for qid=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kirill\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \"\"\"\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kirill\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    394\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32mC:\\Users\\Kirill\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# no dtype conversion required\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time clf1 = clf1.fit(X_train, y_train, q_train, queries_train, X_test, y_test, q_test, queries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xcef40b8>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njHblfqenXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x85e0cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Визуализация\n",
    "axis_x = map(lambda x: x[0], results_buf1)[1:100]\n",
    "train_y1 = map(lambda x: x[1], results_buf1)[1:100]\n",
    "test_y1 = map(lambda x: x[2], results_buf1)[1:100]\n",
    "train_y2 = map(lambda x: x[1], results_buf2)[1:100]\n",
    "test_y2 = map(lambda x: x[2], results_buf2)[1:100]\n",
    "#pylab.plot(axis_x, train_y)\n",
    "pylab.plot(axis_x, test_y1)\n",
    "pylab.plot(axis_x, test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13c17cc0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9a387b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "axis_x = map(lambda x: x[0], results_buf1)[1:]\n",
    "train_y = map(lambda x: x[1], results_buf1)[1:]\n",
    "test_y = map(lambda x: x[2], results_buf1)[1:]\n",
    "#pylab.plot(axis_x, train_y)\n",
    "pylab.plot(axis_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x163685c0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axis_x2 = map(lambda x: x[0], results_buf2)[1:]\n",
    "train_y2 = map(lambda x: x[1], results_buf2)[1:]\n",
    "test_y2 = map(lambda x: x[2], results_buf2)[1:]\n",
    "pylab.plot(axis_x2, train_y2)\n",
    "#pylab.plot(axis_x2, test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраним пока данные\n",
    "with open('results_no_fs_300.txt','w+') as fout:\n",
    "    for i, train, test in results_buf2:\n",
    "        s = \"Iteration {}, train_result {}, test_result {}\\n\".format(i, train, test)\n",
    "        fout.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Откроём сохранённые результаты fs\n",
    "with open('results_fs_200.txt','r+') as fin:\n",
    "    results_buf1 = []\n",
    "    lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(' ')\n",
    "        results_buf1.append((int(tokens[1][:-1]), float(tokens[3][:-1]), float(tokens[5])))\n",
    "        #print tokens[1][:-1]\n",
    "        #print tokens[3][:-1]\n",
    "        #print tokens[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Откроём сохранённые результаты no_fs\n",
    "with open('results_no_fs_300.txt','r+') as fin:\n",
    "    results_buf1 = []\n",
    "    lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(' ')\n",
    "        results_buf2.append((int(tokens[1][:-1]), float(tokens[3][:-1]), float(tokens[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x9f852b0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xmc1PV9x/HXh0s5VA45IiLRqlxV0Bg19dpEotgYMbZJ\nIG08ooYYUaKtgkkb0KSJSCRJY0w1EkONqTVGA+RQvNZUMQqCF1kEEZDlFPBguXf59I/PjDvszOwO\n7M7MzvB+Ph489nfP98vs/j6/7/kzd0dERCRVm2InQEREWh8FBxERSaPgICIiaRQcREQkjYKDiIik\nUXAQEZE0OQUHMxthZovMbLGZjc+wf4CZzTGz7WZ2fYN915nZ62b2qpndb2YdEtu7mdlsM3vDzB4z\ns0NaJksiItJcTQYHM2sD3AGcCwwBRpvZwAaHbQSuAaY0OPewxPYT3f14oB0wKrF7AvCEuw8AngJu\nakY+RESkBeVScjgZWOLuK9x9F/AAMDL1AHff4O4vAbUZzm8LdDazdkAnYFVi+0hgemJ5OnDhPqRf\nRETyIJfg0BdYmbJendjWJHdfDdwOvE0Ehffc/cnE7l7uvi5x3FqgV66JFhGR/Mprg7SZdSVKCP2B\nw4AuZvalLIdrHg8RkVaiXQ7HrAKOSFk/nPqqoaYMB95y900AZvYw8HfAr4F1Ztbb3deZWR9gfaYL\nmJmChojIPnB329dzcyk5zAWONrP+iZ5Go4CZjRyfmpi3gVPN7EAzM+BsoCqxbyZwaWL5EmBGtgu6\ne9n+mzhxYtHToPwpb8pf+f1rriZLDu5eZ2ZjgdlEMJnm7lVmNiZ2+91m1huYBxwE7DazccBgd3/R\nzB4CFgC7Ej/vTlx6MvCgmX0FWAF8odm5ERGRFpFLtRLu/igwoMG2u1KW1wH9spx7M3Bzhu2biGon\nERFpZTRCusgqKiqKnYS8Kuf8lXPeQPnb31lL1E3lk5l5a0+jiEhrY2Z4nhukRURkP6PgICIiaRQc\nREQkjYKDiIikUXAQEZE0Cg4iIpJGwUFERNIoOIiISBoFBxERSaPgICIiaRQcREQkjYKDiIikUXAQ\nEZE0Cg4iIpJGwUFERNIoOIiISBoFBxERSaPgICIiaRQcREQkjYKDiIikUXAQEZE0OQUHMxthZovM\nbLGZjc+wf4CZzTGz7WZ2fcr2Y81sgZnNT/x838yuTeybaGbViX3zzWxEy2VLRFrS7t31/2T/YO7e\n+AFmbYDFwNnAamAuMMrdF6UccyjQH7gQeNfdp2a5TjVwsrtXm9lEYHOmYxuc502lUUTyY+dOuO46\n+MUvYMeO2DZ4MPTrF8tf/jJ86UvFS59kZ2a4u+3r+e1yOOZkYIm7r0h84APASODD4ODuG4ANZnZ+\nI9cZDix19+qUbfuccBHJv9mz4S9/gbffhp49obYWXn4Z3nkH1q+HG26AL3wB2uVyJ5GSkku1Ul9g\nZcp6dWLb3voi8D8Nto01s5fN7B4zO2QfrilSkl54Af7jP+DZZ6E1F4wffjhKBz17xnq7dnDSSXDe\neXDJJfDRj8Lvf1/UJEqeFCTem1l74AJgQsrmO4Fb3N3N7LvAVODyTOdPmjTpw+WKigoqKiryllaR\nfNuxA0aNgnPPhcsui/WDDoJevWDXLjjuOPjc5+CYY+rPWbkSXn+9PpC0aRNVO3//97HcXOvXQ6dO\n0KVL/bbaWpg1CyZOzH7edddFyaFvXxg7FjZtijwkdesW/6yROoLDDoOBAyNvHTvWV1nJ3qmsrKSy\nsrLFrpdLm8OpwCR3H5FYnwC4u0/OcGzGdgQzuwD4evIaGc7rD8xy9+Mz7FObg7R6774LNTXw5JOw\nbFnmY9q3j2Bw111RNTNzJtTVxfHbtsUNum1bmDcPfvObWE/q2RNOOKG++qauLj7rm9+MazbHY4/B\n6NGwffuepRh3OPVUaOp+s20bvPQSTJsWJYmOHevP37gR3n8/+7m7d8OqVVBVFUGyd29YsKB5+ZHQ\n3DaHXIJDW+ANokF6DfAiMNrdqzIcOxGocffbG2z/H+BRd5+esq2Pu69NLF8HfNzd05q2FByktdqw\nAT7xCVi3LtY7d46b6dChmZ+U16+HX/4ynpIfegiOPLJ5n/+nP8G3vhU35saezAHeeguqq9O3z50L\nt90W1UennLLnUz9Ahw4RsAph92446qhIy4knFuYzy1neg0PiQ0YAPybaKKa5+61mNoYoQdxtZr2B\necBBwG6gBhjs7jVm1glYARzl7ptTrvnfwLDE8cuBMe6+LsNnKzgUybvvxs2hc+dip6R1+sEPogRw\nxx1wyCFN36AhAkrXri3TgLt7dwSaAQPgjTdgyRL4yEeiqun99+EPf4jSQJ8+UdIYMCD9Gl27wg9/\nCH/zN81PT0v4zndg7Vr46U+LnZLSV5DgUEwKDi1r1aq4WeTyNPjVr8Kxx8K//mv+01VK3KP+/6KL\n4L77orRQLEuWRDXM0UfDsGERJJ5+OtoPzj8/bv4rV8Lhh0e1Vmu3cmXkY+XKyIPsu0J0ZZUy8d57\nUW89aRJ8/etNH//mmy3T2Flqdu6MElM2v/kNXH119Ng55ZTCpSuTY47Zs+F60KD4l6q51VeF1K9f\n/J/+9rfRSyrVmjXRcJ/aaC75o5JDmXOProYffBDVDEuWRAPi00/HH9ugQdmfKI88Mm48s2cXNs3F\n9Mc/wjXXxBN4tqqff/onOOusKFlJy3v4Yfi3f4PPfjbWd+2C//u/qMK79lq4/fbGz5egaiVp1GOP\nwRVXwJlnRi+S738/ltesge7do0H1/vvTz6uthQMPjN4nL7wQjZlDhxY8+QV35pnw6qsxIviii9L3\n19ZGj5pXX43um9Lyamvh5z+PBxqItpyPfxwOOACuvBIWLixu+lra5s2wZUv2/du3x99rXV38TX7s\nY7m1b6laSRp1xx3RT/2KK+q33X9/BIqPfAT694+G527d9jyvuhp69Ii637vvhmeegUcfLWzaC23u\n3BgJfMcdMUBt27Zo2E3twbNmTfyfKTDkT7t2cNVV6dvr6qKxuro62lDKwaZN0V7UWDVmhw7xt9q+\nPSxeHA8u5zc2F0ULUXAokldfhSFD8ttNcMUKeP55+N//3XN7ajfBc8+FBx+EMWP2PGbZsujdsmxZ\nBJPkvDrl7K674Gtfgy9+MdpbZs2KBt0DDtjzuClTipO+/V3btjB8ODz+ePPHdrSU55+Pv58nnoCl\nS+u3DxoUDxtNtdlNnx69y371q9w+7z//M9pjChEccPdW/S+SWHq++lX3Z57JvG/XLvcuXdx/9avm\nf86WLdn3TZnifuWVjZ//yCPuw4enb582zf3ii93PPNMd3Dt0iHSXq82b3bt2dV+9utgpkcb88pfu\n559f7FSEnTvdDzvM/eab3efMca+pib/HLVvcBw1y/8tfGj9/9273AQPc//zn3D9zxQr3Hj1y+1tM\n3Dv3+d6rkkMevPpqVMUcfHDUYWfaX1cHt94aI1P3pkfQxo31M2Ru3Bifs3Fj1EU29NvfRs+kxpx2\nWjyFJZt1Jk+GceOixHDkkZG29eujTnTlytLq+bI3HnkETj89iu/Sev3DP8SUHStXZp9m44MPYj/E\n1BwNq0xzVVUV1Vju0T43bNie+3/3u6gS+va308/93OfqBxZm89OfRtpOPz33NB1xRPwNfupT9eOP\nTj89BkO2NAWHvfDyyzHvTVNVQbfeCiNGwJw5mfc/+yz88z/Diy9GT6ARe/Emi1tuiZ40Q4dGl8ue\nPaM4O2RIDIpKBprq6qif/OQnG79ez57RPfCtt6Lh66aboki8dGlUOR14YLRPVFXFtnINDk8/HcV7\nad26dIkpwm+8MW6Q77wTvfG2bo39u3fD8uXRJrF7d9zYq6r2vku2ezy4mcVNeOnSmHCwb9/4+fDD\nMH8+/OQnmc+/6KL4u541K9J3771R/QQRaA47DP7857hH5NK4nOqRR+C11+rXe/feu/NzVZa9lXbt\nil+eH/6w5dLxq1/BxRfH9AcXX5z9uBUrok7/9dfjqWLTpqiz/v3vo15y7NiI8p/5TDR4zp4dT/i5\n2Lo1npYWLIgnCICRI2N2zIsuimuOGBFdMW+/PdJw771NX/fCC+MPbtGiaIw9/fRogJ4/v3507bXX\nRo+Rhm0T5WLAgBi/cHza7F7S2rz9Nnzve/F7mRzsl5w1FmIKjoMPjhv8CSfESPbhw/fuM154Ibos\nL14cgWXTpvhbra6G556Dz38+unmfdFLmm7t73H8WLIjzZ86Ep56K9K5bFyWSoUMzj1pvKerKmsHy\n5fGEW1PTMlM/bN8ev3zf/W5U47z2WvYnkeuvj5LFlCnR5ewnP4lRyTfeCP/4j3Gz3rIlbtw9e0bP\nl0WLcov+v/hFPLGkTpF8443RaDpyZFRhtW0bv9BnnBE3+rPOavq63/lO/F89+iiMHx9/FKNHw69/\nXX/M978fvZpuu23Pc2fMiGBYyjNpbtgQ00ds2lS4eYSkMH72s/g9Hj266WPXr48A0K9fjAcaNSr+\nvppj6dIIIpdfHt1zC0nBIeEPf4BXXolZKp97Lp5+q6pi7pnmeu65qIefOzduhFOmZH4See+9eGp5\n5ZX4BbvuuphzZ+HCqLK47LK4AT32WPzimcFXvhJVQv/yL3teyz2eeMaNi65s7vGkMWVKVPckTZsW\nxdNOnSLArF0bPShqaqLHTS5F1j/+MQLXgAExI+ill8ZLXFKfoh98MNojPvWpuJnOnh15fe65qHNt\nqm2jNZs1K4L4/jTYb39RUwM339z4OIKkLl3g05+OJ/u6uigdtMQUHt/+dlQjH3ts86+1NzTOIWHh\nwqgGgXhShyh+tkRweP75GCxmFkXYp5/OHBx+/vMIAsmn6MsuiykWtmypn0ise/c9n2K+9CWYMKE+\nOPz1r9HH/qqr6utV58+PkgbAOefs+ZkDBkQV0tq18X/Qq1d0yezRI/e6zDPPjBGp3/hGPDnfd1/6\nMaeeGk/X3btHqeyGG6IEdcUVUdVWyp55Bv7u74qdCsmHLl2K3/X4lluK+/n7rDldnQrxjxy7so4f\n7/7JT8by1KnR/fKee3I6tUkXXeT+61/H8qOPup9xRvoxdXXuhx/uPn/+ntvPPNP9tNOyX7u21r13\nb/fFi2P9vPPcO3d2P/JI944d3X/2s7juZz7j/rvfpZ+/fn3kdfTofctbc73/fqR3+/bifH5z1dZG\nd8TXXy92SkRaFurKGjZtijpxiJJD585Rcmgu9+hRkJzP5ROfiCf5HTv2HBy1Zk00hJ9wwp7n/+AH\njb/spG3baFA+88xo/K2piXaF88+PnkMPPhhF3FmzMpcEDj00SgvXXNP8vO6Lgw+O0tmLL0Y7R6l5\n/PHogTJkSLFTItK6lG1wOPnk+r7OzbFmTcz10r9/rB98cFTlzJ0bRdY//SluzNn6XX/8401/xve/\nH3PGvPdeVN106xa9IpYvjyJpsn0iE7NoW+nefZ+z2GxnnRVVM6UQHNzhnnuiC+SOHdFYqSnJRdKV\nzYTM7767Z3A49dSWKTm8+WY0JKXenM87L6aUmDgxfn7xi40PymlKmzbR7fWkk+oH7PTqFQ3C7do1\n3eOomIEB6oNDKZgzJ3qd1dRE0P/ZzyIwi8ieyqrk8MEH8QefDA7J8QPuuTfOVlZGVU/yKXjp0vS3\nZI0bF6WHtm2jt85ZZ8HZZ7d8d84DD4wG670ZJFcMZ5wR3V937Wr9L5S5554Ya3LDDcVOiUjrVjYl\nh02b4ud778Hq1REcVq6MG9YnPtH0S9KT/uu/oiSQbCd48814qk/Vs2f0LvrGN6IPc01N9CbKR1//\n6dNj2uzWrFu3CKDz5hU7JZm98kp01928OUaXNjaIUURCWQWHnj3jZn7AAVEt06dPPNG/8ELMFZSL\n116Lrpq33hrrmUoOEKOcv/WtKJEce2yMfi7lgWDNddZZMUDuqaeKnZJ6S5fGyPZzzonuwk89FVV3\n+ZpuQKSclEVw2LkzRjEfcUT9ADSI8Qkf+1hMLZFsj2jMjh0xx9CPfhTTXLtnLjk0NHBg89ocysGY\nMTHg75vfLHZK6o0bF4MEb789Gvjvuy8GOYlI08oiOLz7bjTKdu8evYiSN/PevWN+k2HD6qudGrNo\nUZQaTjopJu1auDCCQ6aSQ6rk/Cj7c3AYPDhuwlVV9TO8FtP27TFy/OGHY3Tqpz4VbVAKDiK5KYvg\nsGlTBIZu3SI4pL5wHWJfU8GhsjL+HXdcVBVdcEFMqeAeo40bM3BgNE7v79M99+gRjehr1hQ7JdF7\naujQ+t5fn/50jAlpOO2yiGRWVsGhe/doGG4YHLp1a7pa6corY9K8446L9csvj0AzYkTTPZ2GDIkq\nrWwvpN+fDBoUU4AU0+OPw9Sp0eU46fOfj84Gezt1s8j+Kqc/FTMbYWaLzGyxmY3PsH+Amc0xs+1m\ndn3K9mPNbIGZzU/8fN/Mrk3s62Zms83sDTN7zMwO2ddMpJYcdu9ObyNoquSwbVvUSU+cCJ/9bGwb\nOjRGQjd8xWYmQ4ZEo7dEcKiq2nPbzp3xQqLkvzffjMC7Zk39S+QbWr065nv63vfiPRq52rYtJhEc\nPBi+/OX67d27x4tiRCQ3TT7rmlkb4A7gbGA1MNfMZrj7opTDNgLXABemnuvui4ETUq5TDTyc2D0B\neMLdb0sEnJsS2/ZaanCAvS85LFqU/Y1OuUqdT35/1jA4rFoVU4O89179toMPju9k1ap4R8Vll0Xp\nrHfvaNju0SOmEV+zJtp7zjwzRjQ3fJdzJk8+GVVHLfkuD5H9US4lh5OBJe6+wt13AQ8AI1MPcPcN\n7v4SUNvIdYYDS929OrE+EpieWJ5Og8CyN1KDQ8eO8ZalVE2VHBYu1Nw6LWXQIHjooaieO++8aNy/\n8so9Sw7LlkWpbN26mDf/wAPjzV0LFkSgeP99eOABuPPOaOQeODB6nuVixox4eZGINE8uteR9gdRZ\niqqJgLG3vgj8T8p6L3dfB+Dua82s1z5cE4hSQdeuEQSOPjq9XrmpkoOCQ8s5/fR46j/xxHjyP+aY\nCBjZ9OlT/wKhnTtjLqoTToi2nmSQHz48SgQVFennr1kTY1POOiveN/HQQ/DSSy2eLZH9TkGaUM2s\nPXABjVcbZe0AOSnlTTIVFRVUNLhLbN0aPYVOOSXztAhdu8bTaOo7llMtXBgvuJHm69hx318l2qFD\nDFR76y3427+t33722fDv/x5BJ9Urr0QpYfPmqNY75ph418ZRR+17+kVKVWVlJZW5TgWRgybfBGdm\npwKT3H1EYn0CMU/45AzHTgQ2u/vUBtsvAL6evEZiWxVQ4e7rzKwP8LS7pz1j5vImuK9/Paoxrroq\n+zFdu0Z1RrJdAqKq6dZb49Wf8+Y1PdhNimP79phWO7VqsG/fmBpl6tQoUfz2t3D11XrNp0hSId4E\nNxc42sz6A2uAUUBjb2TNlJjR7FmlBDATuBSYDFwCzMghLRlt3RpPrI1JVi0lg8O770bD5fnnx9QX\nCgyt14EHxqtJk9xjOvPu3SPoA1x7bVGSJlK2mgwO7l5nZmOB2UQD9jR3rzKzMbHb7zaz3sA84CBg\nt5mNAwa7e42ZdSIao7/a4NKTgQfN7CvACuAL+5qJrVubftdrslE6WeXw9NNRdXHnnfv6qVJIqWNN\nzFR1JJJvObU5uPujwIAG2+5KWV4HZJw8wt23AmkdPd19ExE0mi2X4NCwUbqyMnMDp4iIlMkI6b0p\nOSQ980zTL9EREdlf7TfB4dBDoxcMRJBYtiy6W4qISLr9JjhcdVX0bFm9OqZuOOmk1v/WMhGRYimL\nqeJyCQ7HHQeXXBIBol+/mHtHREQy229KDgDnnhujZxctiikZREQks/0qOAwdGjN8VlUpOIiINKbJ\nEdLFlssI6Q4doKYmfjalb9/6aaMPP7yFEiki0so0d4R0yZccdu2KOZNybVweNixeytO3b37TJSJS\nykq+QXrbtqhSauptbUnDhsVU0bkeLyKyPyr54JBre0PS8OF6naeISFNKvs3hrbdiSudlywqYKBGR\nVm6/b3PY25KDiIg0TcFBRETSKDiIiEiakg8Oyd5KIiLScko+OKjkICLS8hQcREQkjYKDiIikUXAQ\nEZE0Cg4iIpJGwUFERNIoOIiISJqyCA4dOxY7FSIi5SWn4GBmI8xskZktNrPxGfYPMLM5ZrbdzK5v\nsO8QM/uNmVWZ2UIzOyWxfaKZVZvZ/MS/EfuSgQ8+gIMO2pczRUQkmyYnrzazNsAdwNnAamCumc1w\n90Uph20ErgEuzHCJHwN/dPfPm1k7ILUSaKq7T93n1BNvdTv00OZcQUREGsql5HAysMTdV7j7LuAB\nYGTqAe6+wd1fAmpTt5vZwcAZ7n5v4rhad/8g9ZBmpR7YsEHBQUSkpeUSHPoCK1PWqxPbcnEksMHM\n7k1UHd1tZqktBGPN7GUzu8fMDsnxmntQcBARaXn5fidaO+BE4Gp3n2dmPwImABOBO4Fb3N3N7LvA\nVODyTBeZNGnSh8sVFRVUVFR8uK7gICIClZWVVFZWttj1mnwTnJmdCkxy9xGJ9QmAu/vkDMdOBDYn\n2xHMrDfwvLsflVg/HRjv7p9tcF5/YJa7H5/hmlnfBLd1K/ToET/1TmgRkXqFeBPcXOBoM+tvZh2A\nUcDMxtKUXHD3dcBKMzs2sels4K8AZtYn5ZyLgNf3JuEQpYYePRQYRERaWpPVSu5eZ2ZjgdlEMJnm\n7lVmNiZ2+92JEsI84CBgt5mNAwa7ew1wLXC/mbUH3gIuS1z6NjMbBuwGlgNj9jbxqlISEcmPJquV\niq2xaqXHH4fJk+GJJwqcKBGRVq4Q1UqtlkoOIiL5oeAgIiJpFBxERCSNgoOIiKQp+eDQo0exUyEi\nUn5KOjhs3KjgICKSDyUdHLZsgS5dip0KEZHyU9LBQW+BExHJDwUHERFJU9LBYds2BQcRkXwo6eCg\nkoOISH4oOIiISJqSDQ51dbBzJxxwQLFTIiJSfko2OGzbBh076l0OIiL5ULLBQVVKIiL5U7LBQT2V\nRETyp2SDg0oOIiL5o+AgIiJpFBxERCRNSQeHjh2LnQoRkfJUksHhscdUchARyaeSDA7nnw+rVys4\niIjkS8kFB3eorYUVKxQcRETyJafgYGYjzGyRmS02s/EZ9g8wszlmtt3Mrm+w7xAz+42ZVZnZQjM7\nJbG9m5nNNrM3zOwxMzskl7TU1sZPBQcRkfxpMjiYWRvgDuBcYAgw2swGNjhsI3ANMCXDJX4M/NHd\nBwFDgarE9gnAE+4+AHgKuCmXBCeDw/LlCg4iIvmSS8nhZGCJu69w913AA8DI1APcfYO7vwTUpm43\ns4OBM9z93sRxte7+QWL3SGB6Ynk6cGEuCd61K36+/baCg4hIvuQSHPoCK1PWqxPbcnEksMHM7jWz\n+WZ2t5klO6D2cvd1AO6+FuiVywWTwWHtWnVlFRHJl3YFuP6JwNXuPs/MfkRUJ00EGs6n6tkuMmnS\npA+Xjz++AqgAVHIQEUmqrKyksrKyxa6XS3BYBRyRsn54YlsuqoGV7j4vsf4QkGzQXmtmvd19nZn1\nAdZnu0hqcKiurt+u4CAiEioqKqioqPhw/eabb27W9XKpVpoLHG1m/c2sAzAKmNnI8R+WCBLVRivN\n7NjEprOBvyaWZwKXJpYvAWbkkuBktRIoOIiI5EuTJQd3rzOzscBsIphMc/cqMxsTu/1uM+sNzAMO\nAnab2ThgsLvXANcC95tZe+At4LLEpScDD5rZV4AVwBdySbCCg4hI/pl71qr+VsHMPDWNCxfCqadC\nTQ088QScfXYREyci0kqZGe6+z+/KLLkR0rW1cNhhsaySg4hIfpRccNi1Cw46CLp0UVdWEZF8Kcng\n0L49fPSj0L17sVMjIlKe8j3OocUlg8P8+fFTRERaXkmWHNq1U2AQEcmnkgsOtbUKDCIi+VZywSFZ\nrSQiIvmj4CAiImlKMji0K7lmdBGR0lJywUFtDiIi+VdywUHVSiIi+afgICIiaUoyOKjNQUQkv0ou\nOKjNQUQk/0oiOOzaBRs21C8rOIiI5FdJBIdHH4WvfS2WFRxERPKvJILDtm2wZUssq81BRCT/SiI4\n1NbCjh2xrJKDiEj+lUxw2LmzflnBQUQkv0omOKjkICJSOCUTHJIlB7U5iIjkX0kEh7o6lRxERAqp\nJIKD2hxERAorp+BgZiPMbJGZLTaz8Rn2DzCzOWa23cyub7BvuZm9YmYLzOzFlO0TzazazOYn/o3I\n9vlqcxARKawma+/NrA1wB3A2sBqYa2Yz3H1RymEbgWuACzNcYjdQ4e7vZtg31d2nNpWGhsFBbQ4i\nIvmVS8nhZGCJu69w913AA8DI1APcfYO7vwTUZjjfGvkcyyWRDRukVXIQEcmvXIJDX2Blynp1Yluu\nHHjczOaa2ZUN9o01s5fN7B4zOyTbBVJLDmpzEBHJv0JU0Jzm7mvMrCcRJKrc/VngTuAWd3cz+y4w\nFbg80wWefHISO3fCxImwZk0F7dtXFCDZIiKlo7KyksrKyha7Xi7BYRVwRMr64YltOXH3NYmf75jZ\nI0Q11bPu/k7KYT8HZmW7xumnT+KZZ+Bb34J589TmICLSUEVFBRUVFR+u33zzzc26Xi7VSnOBo82s\nv5l1AEYBMxs5/sN2BDPrZGZdEsudgXOA1xPrfVLOuSi5PZPaREvGjh1qcxARKYQmn8Hdvc7MxgKz\niWAyzd2rzGxM7Pa7zaw3MA84CNhtZuOAwUBP4BEz88Rn3e/usxOXvs3MhhG9mZYDY7KlIRkcdu5U\ncBARKYScKmjc/VFgQINtd6UsrwP6ZTi1BhiW5ZoX55rI1JKDGqRFRPKvZEZIQ33JQW0OIiL5VRLB\noa4ufqrNQUSkMEoiOKjNQUSksEoqOKjNQUSkMEouOKjNQUQk/0oqOKhaSUSkMEoiOKhBWkSksEoi\nOKSWHNTmICKSfyUTHNq3V5uDiEihlExw6NxZbQ4iIoVSUsFBbQ4iIoVRMsGhUyeNcxARKZSSCA51\ndfXBoa4O2rYtdopERMpbSQSHZMlhy5ZojLac3jwtIiL7qmSCQ+fOUFOjKiURkUIomeCQLDkoOIiI\n5F9JBYeKraUDAAAH8ElEQVSaGo1xEBEphJIKDuvXwyGHFDs1IiLlrySCQ11dtDksWQL9+xc7NSIi\n5a8kgkOyQXrZMjjiiGKnRkSk/JVMcOjUKUZHKziIiORfyQSHzp1jWcFBRCT/SiY4dOoUywoOIiL5\nl1NwMLMRZrbIzBab2fgM+weY2Rwz225m1zfYt9zMXjGzBWb2Ysr2bmY228zeMLPHzCxrP6Tk9Bmg\n4CAiUghNBgczawPcAZwLDAFGm9nABodtBK4BpmS4xG6gwt1PcPeTU7ZPAJ5w9wHAU8BN2dKQWnLo\n16+pFIuISHPlUnI4GVji7ivcfRfwADAy9QB33+DuLwG1Gc63LJ8zEpieWJ4OXJgtAck2h+7doUuX\nHFIsIiLNkktw6AusTFmvTmzLlQOPm9lcM7syZXsvd18H4O5rgV7ZLlBbCz17wrHH7sWniojIPivE\nZBSnufsaM+tJBIkqd382w3Ge7QI7dkxixgwYPhwqKyuoqKjIW2JFREpRZWUllZWVLXY9c896T44D\nzE4FJrn7iMT6BMDdfXKGYycCm919apZrfbjfzKqItoh1ZtYHeNrdB2U4x8Gpq4M2JdG3SkSk+MwM\nd9/nFxzkcrudCxxtZv3NrAMwCpjZWJpSEtfJzLokljsD5wCvJ3bPBC5NLF8CzMh6QVNgEBEppCZL\nDhBdWYEfE8FkmrvfamZjiBLE3WbWG5gHHET0TqoBBgM9gUeIKqN2wP3ufmvimt2BB4F+wArgC+7+\nXobP9vbtnZ07m51XEZH9RnNLDjkFh2IyM+/Y0dm6tdgpEREpHYWoVio6vcNBRKSwSiI4tG1b7BSI\niOxfSiI4qOQgIlJYCg4iIpJGwUFERNIoOIiISBoFBxERSVMSwUG9lURECqskgoNKDiIihaXgICIi\naRQcREQkjYKDiIikUXAQEZE0JREc1FtJRKSwSiI4qOQgIlJYCg4iIpJGwUFERNIoOIiISBoFBxER\nSVMSwUG9lURECqskgoNKDiIihaXgICIiaXIKDmY2wswWmdliMxufYf8AM5tjZtvN7PoM+9uY2Xwz\nm5mybaKZVSe2zzezEdk+X8FBRKSwmgwOZtYGuAM4FxgCjDazgQ0O2whcA0zJcplxwF8zbJ/q7icm\n/j2aLQ3lHBwqKyuLnYS8Kuf8lXPeQPnb3+VScjgZWOLuK9x9F/AAMDL1AHff4O4vAbUNTzazw4G/\nB+7JcG3LJZHl3CBd7r+g5Zy/cs4bKH/7u1yCQ19gZcp6dWJbrn4I3AB4hn1jzexlM7vHzA7JdoFy\nLjmIiLRGeW2QNrPPAOvc/WWilJBaUrgTOMrdhwFrganZrvPJT+YzlSIi0pC5Z3qgTznA7FRgkruP\nSKxPANzdJ2c4diKw2d2nJta/B/wzUd3UETgIeNjdL25wXn9glrsfn+GajSdQREQycvecqu4zyaXC\nZi5wdOIGvgYYBYxu5PgPE+Pu3wS+CWBmZwH/kgwMZtbH3dcmDr0IeD3TxZqTORER2TdNBgd3rzOz\nscBsohpqmrtXmdmY2O13m1lvYB5RMthtZuOAwe5e08ilbzOzYcBuYDkwppl5ERGRFtJktZKIiOx/\nWu0I6aYG3pUiM1tuZq+Y2QIzezGxrZuZzTazN8zsscZ6bbU2ZjbNzNaZ2asp27Lmx8xuMrMlZlZl\nZucUJ9W5y5K/rIM3Syl/Zna4mT1lZgvN7DUzuzaxvSy+vwz5uyaxvVy+vwPM7IXEveS1RHtvy35/\n7t7q/hFB602gP9AeeBkYWOx0tUC+3gK6Ndg2GbgxsTweuLXY6dyL/JwODANebSo/wGBgAVGV+dHE\n92vFzsM+5G8icH2GYweVUv6APsCwxHIX4A1gYLl8f43kryy+v0SaOyV+tgX+QoxJa7Hvr7WWHJoc\neFeijPTS2khgemJ5OnBhQVPUDO7+LPBug83Z8nMB8IC717r7cmAJ8T23WlnyB5kHb46khPLn7ms9\nupjj0TZYBRxOmXx/WfKXHJ9V8t8fgLtvTSweQNz0nRb8/lprcGjuwLvWyoHHzWyumV2R2Nbb3ddB\n/EIDvYqWupbRK0t+Gn6nqyjd7zTT4M2SzZ+ZfZQoIf2F7L+P5ZC/FxKbyuL7S8xZt4AYJ/a4u8+l\nBb+/1hocytVp7n4iMZ3I1WZ2Bukjx8uth0C55afh4M3bi5yeZjGzLsBDwLjEE3ZZ/T5myF/ZfH/u\nvtvdTyBKfCeb2RBa8PtrrcFhFXBEyvrhiW0lzd3XJH6+A/yOKNatS3QFxsz6AOuLl8IWkS0/q4B+\nKceV5Hfq7u94ohIX+Dn1RfOSy5+ZtSNunPe5+4zE5rL5/jLlr5y+vyR3/wCoBEbQgt9faw0OHw68\nM7MOxMC7mU2c06qZWafEUwxm1hk4B3iNyNelicMuAWZkvEDr1XBalGz5mQmMMrMOZnYkcDTwYqES\n2Qx75C/xB5eUOnizFPP3C+Cv7v7jlG3l9P2l5a9cvj8zOzRZJWZmHYFPE+0qLff9FbvFvZGW+BFE\nD4MlwIRip6cF8nMk0etqAREUJiS2dweeSOR1NtC12Gndizz9GlgN7ADeBi4DumXLD3AT0UuiCjin\n2Onfx/z9N/Bq4rv8HVHHW3L5A04D6lJ+J+cn/uay/j6WSf7K5fs7LpGnlxP5+VZie4t9fxoEJyIi\naVprtZKIiBSRgoOIiKRRcBARkTQKDiIikkbBQURE0ig4iIhIGgUHERFJo+AgIiJp/h8n/m+eox3Q\n6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x864f588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "axis_x1 = map(lambda x: x[0], results_buf2)[1:]\n",
    "train_y1 = map(lambda x: x[1], results_buf2)[1:]\n",
    "test_y1 = map(lambda x: x[2], results_buf2)[1:]\n",
    "#pylab.plot(axis_x, train_y)\n",
    "pylab.plot(axis_x1, test_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Визуализация\n",
    "axis_x = map(lambda x: x[0], results_buf1)[:200]\n",
    "train_y1 = map(lambda x: x[1], results_buf1)[:200]\n",
    "test_y1 = map(lambda x: x[2], results_buf1)[:200]\n",
    "train_y2 = map(lambda x: x[1], results_buf2)[1:200]\n",
    "test_y2 = map(lambda x: x[2], results_buf2)[1:200]\n",
    "#pylab.plot(axis_x, train_y)\n",
    "pylab.plot(axis_x, test_y1)\n",
    "pylab.plot(axis_x, test_y2)\n",
    "blue_patch = mpatches.Patch(color='blue', label='With feature selection')\n",
    "green_patch = mpatches.Patch(color='green', label='No feature selection')\n",
    "pylab.legend(handles=[blue_patch, green_patch])\n",
    "pylab.xticks(np.arange(0, 201, 20))\n",
    "pylab.yticks(np.arange(0.14, 0.21, 0.005))\n",
    "pylab.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <a list of 6 Text xticklabel objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты на 5000 элементах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 200\n",
    "clf2 = LambdaMART(n, alpha=0.5, beta=1., feature_subset=True, feature_fraction=0.3)\n",
    "clf1 = LambdaMART(n, alpha=0.5, beta=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1  result  0.0287593537783\n",
      "Iteration  31  result  0.852402040229\n",
      "Iteration  61  result  0.918656263683\n",
      "Iteration  91  result  0.935536614135\n",
      "Iteration  121  result  0.935536614135\n",
      "Iteration  151  result  0.935536614135\n",
      "Iteration  181  result  0.935536614135\n",
      "Wall time: 5h 40min 27s\n"
     ]
    }
   ],
   "source": [
    "%time clf2 = clf2.fit(X_full_train, y_full_train, q_full_train, queries_full_train, X_test, y_test, q_test, queries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1  result  0.24469999225\n",
      "Iteration  31  result  0.803626307519\n",
      "Iteration  61  result  0.802526356657\n",
      "Iteration  91  result  0.802526356657\n",
      "Iteration  121  result  0.805159791912\n",
      "Iteration  151  result  0.868780580111\n",
      "Iteration  181  result  0.805159791912\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bba5a5d603af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time clf1 = clf1.fit(X_full_train, y_full_train, q_full_train, queries_full_train, X_test, y_test, q_test, queries_test)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\Programs\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\lib\\site-packages\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\lib\\site-packages\\IPython\\core\\magics\\execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9a8df8d650bb>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, qids_train, queries_train, X_test, y_test, qids_test, queries_test, verbose)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mqueries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueries_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Grad:\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9a8df8d650bb>\u001b[0m in \u001b[0;36mloss_grad\u001b[0;34m(self, pred_y, y, id_y)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdelta_ndcg\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdelta_ndcg\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9a8df8d650bb>\u001b[0m in \u001b[0;36mrho\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time clf1 = clf1.fit(X_full_train, y_full_train, q_full_train, queries_full_train, X_test, y_test, q_test, queries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 1 0.5 0.336099646865 0.334095124305\n",
      "0.5 1 1.0 0.284810928463 0.336022586491\n",
      "0.5 1 2.0 0.278983133131 0.235084867792\n",
      "0.5 2 0.5 0.41276830698 0.325806649599\n",
      "0.5 2 1.0 0.269452898252 0.219380711384\n",
      "0.5 2 2.0 0.357579678573 0.328906145272\n",
      "0.5 5 0.5 0.360515329939 0.291737452324\n",
      "0.5 5 1.0 0.396132881545 0.352325317071\n",
      "0.5 5 2.0 0.357491363348 0.307072058994\n",
      "0.5 7 0.5 0.307196757893 0.243569464569\n",
      "0.5 7 1.0 0.468726043507 0.381784322914\n",
      "0.5 7 2.0 0.433379695178 0.35421116786\n",
      "1.0 1 0.5 0.298903738381 0.329808291355\n",
      "1.0 1 1.0 0.452061919927 0.348656410939\n",
      "1.0 1 2.0 0.43510791712 0.279133197285\n",
      "1.0 2 0.5 0.298245437817 0.270975813759\n",
      "1.0 2 1.0 0.426176753028 0.298526360796\n",
      "1.0 2 2.0 0.30197343755 0.296332263381\n",
      "1.0 5 0.5 0.444450124696 0.334779000506\n",
      "1.0 5 1.0 0.431277962121 0.373842327464\n",
      "1.0 5 2.0 0.429456655432 0.344643182745\n",
      "1.0 7 0.5 0.438494402494 0.358339454444\n",
      "1.0 7 1.0 0.431007588023 0.367884660402\n",
      "1.0 7 2.0 0.446516329361 0.336559264488\n",
      "2.0 1 0.5 0.259869836501 0.210006019129\n",
      "2.0 1 1.0 0.405543147091 0.281986651447\n",
      "2.0 1 2.0 0.313821884084 0.268496532276\n",
      "2.0 2 0.5 0.458445432413 0.350849454051\n",
      "2.0 2 1.0 0.257580355035 0.30694327258\n",
      "2.0 2 2.0 0.333093525779 0.259259257385\n",
      "2.0 5 0.5 0.34329521534 0.222004082956\n",
      "2.0 5 1.0 0.34956759061 0.263642761974\n",
      "2.0 5 2.0 0.345498792654 0.35035288334\n",
      "2.0 7 0.5 0.442491213356 0.37117135548\n",
      "2.0 7 1.0 0.425625394444 0.319880540672\n",
      "2.0 7 2.0 0.434023061723 0.394820552599\n"
     ]
    }
   ],
   "source": [
    "# Небольшой GridSearch с кросс-валидацией\n",
    "from numpy import unravel_index\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "arr_a = [0.5, 1., 2.] # Одно значение в целях оптимизации\n",
    "arr_L = [1, 2, 5, 7]\n",
    "arr_b = [0.5, 1., 2.] # Одно значение в целях оптимизации\n",
    "\n",
    "results1 = np.zeros((len(arr_a), len(arr_L), len(arr_b))) # С адаптивным шагом\n",
    "results2 = np.zeros((len(arr_a), len(arr_L), len(arr_b))) # Без адаптивного шага\n",
    "\n",
    "for i_a, a in enumerate(arr_a):\n",
    "    for i_L, L in enumerate(arr_L):\n",
    "        for i_b, b in enumerate(arr_b):\n",
    "            for k in xrange(5):\n",
    "                # Перемешаем\n",
    "                shuffle_idx = np.random.permutation(num_elems)\n",
    "                X_train = X[shuffle_idx][:num_elems/2.]\n",
    "                X_valid = X[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "\n",
    "                y_train = y[shuffle_idx][:num_elems/2.]\n",
    "                y_valid = y[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "\n",
    "                q_train = queries[shuffle_idx][:num_elems/2.]\n",
    "                q_valid = queries[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "\n",
    "                queries_train = q[shuffle_idx][:num_elems/2.]\n",
    "                queries_valid = q[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "                \n",
    "                clf1 = LambdaMART(L, alpha=a, beta=b).fit(X_train, y_train, q_train, queries_train)\n",
    "                y_pred1 = clf1.predict(X_valid, q_valid, queries_valid)\n",
    "                results1[i_a, i_L, i_b] += ndcgl(y_pred1, y_valid) / 5.\n",
    "\n",
    "                clf2 = LambdaMART(L, alpha=a, beta=b, adaptive_step=False).fit(X_train, y_train, q_train, queries_train)\n",
    "                y_pred2 = clf2.predict(X_valid, q_valid, queries_valid)\n",
    "                results2[i_a, i_L, i_b] += ndcgl(y_pred2, y_valid) / 5.\n",
    "\n",
    "                # Значения параметров и результаты с адаптивным шагом и без\n",
    "            print a, L, b, results1[i_a, i_L, i_b], results2[i_a, i_L, i_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max with adaptive step - Alpha=0.5, L=7, beta=1.0\n",
      "Max without adaptive step - Alpha=2.0, L=7, beta=2.0\n",
      "Maximum with adaptive step= 0.468726043507\n",
      "Maximum without adaptive step= 0.394820552599\n"
     ]
    }
   ],
   "source": [
    "ad_max = unravel_index(np.argmax(results1), results1.shape)\n",
    "non_ad_max = unravel_index(np.argmax(results2), results2.shape)\n",
    "        \n",
    "print \"Max with adaptive step - Alpha={}, L={}, beta={}\".format(arr_a[ad_max[0]], arr_L[ad_max[1]], arr_b[ad_max[2]])\n",
    "print \"Max without adaptive step - Alpha={}, L={}, beta={}\".format(arr_a[non_ad_max[0]], arr_L[non_ad_max[1]], arr_b[non_ad_max[2]])\n",
    "\n",
    "print \"Maximum with adaptive step=\", np.max(results1)\n",
    "print \"Maximum without adaptive step=\", np.max(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "В принципе, из списка на всех параметрах видны корреляции для адаптивного и неадаптивного методов. И как правило, увеличение числа итераций хорошо влияет на результат. Можно было продолжить и далее, но в виду ограниченных мощностей, пока это не главное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive= 0.473884366146\n",
      "Non-adaptive= 0.328375116338\n"
     ]
    }
   ],
   "source": [
    "result1 = 0.\n",
    "result2 = 0.\n",
    "\n",
    "for k in xrange(5):\n",
    "    shuffle_idx = np.random.permutation(num_elems)\n",
    "    X_train = X[shuffle_idx][:num_elems/2.]\n",
    "    X_valid = X[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    X_test = X[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "    y_train = y[shuffle_idx][:num_elems/2.]\n",
    "    y_valid = y[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    y_test = y[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "    q_train = queries[shuffle_idx][:num_elems/2.]\n",
    "    q_valid = queries[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    q_test = queries[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "    queries_train = q[shuffle_idx][:num_elems/2.]\n",
    "    queries_valid = q[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    queries_test = q[shuffle_idx][num_elems*3./4.:]\n",
    "    \n",
    "    X_full_train = np.append(X_train, X_valid, axis=0)\n",
    "    y_full_train = np.append(y_train, y_valid)\n",
    "    q_full_train = np.append(q_train, q_valid)\n",
    "    queries_full_train = np.append(queries_train, queries_valid, axis=0)\n",
    "    \n",
    "    clf1 = LambdaMART(7, alpha=0.5, beta=1.).fit(X_full_train, y_full_train, q_full_train, queries_full_train)\n",
    "    y_pred1 = clf1.predict(X_test, q_test, queries_test)\n",
    "\n",
    "    clf2 = LambdaMART(7, alpha=2.0, beta=2.0, adaptive_step=False).fit(X_full_train, y_full_train, q_full_train, queries_full_train)\n",
    "    y_pred2 = clf2.predict(X_test, q_test, queries_test)\n",
    "    \n",
    "    result1 += ndcgl(y_pred1, y_test) / 5.\n",
    "    result2 += ndcgl(y_pred2, y_test) / 5.\n",
    "\n",
    "print \"Adaptive=\", result1\n",
    "print \"Non-adaptive=\", result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.349995209906\n"
     ]
    }
   ],
   "source": [
    "# Обычный DecisionTreeRegressor\n",
    "tempresult = 0.\n",
    "\n",
    "for k in xrange(5):\n",
    "    shuffle_idx = np.random.permutation(num_elems)\n",
    "    X_train = X[shuffle_idx][:num_elems/2.]\n",
    "    X_valid = X[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    X_test = X[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "    y_train = y[shuffle_idx][:num_elems/2.]\n",
    "    y_valid = y[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    y_test = y[shuffle_idx][num_elems*3./4.:]\n",
    "    \n",
    "    X_full_train = np.append(X_train, X_valid, axis=0)\n",
    "    y_full_train = np.append(y_train, y_valid)\n",
    "\n",
    "    tempclf = DecisionTreeRegressor().fit(X_full_train, y_full_train)\n",
    "    tempresult += ndcgl(tempclf.predict(X_test), y_test) / 5.\n",
    "    \n",
    "print tempresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.424421739725\n"
     ]
    }
   ],
   "source": [
    "# GDBT\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "tempresult = 0.\n",
    "\n",
    "for k in xrange(5):\n",
    "    shuffle_idx = np.random.permutation(num_elems)\n",
    "    X_train = X[shuffle_idx][:num_elems/2.]\n",
    "    X_valid = X[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    X_test = X[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "    y_train = y[shuffle_idx][:num_elems/2.]\n",
    "    y_valid = y[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    y_test = y[shuffle_idx][num_elems*3./4.:]\n",
    "    \n",
    "    X_full_train = np.append(X_train, X_valid, axis=0)\n",
    "    y_full_train = np.append(y_train, y_valid)\n",
    "\n",
    "    tempclf = GradientBoostingRegressor().fit(X_full_train, y_full_train)\n",
    "    tempresult += ndcgl(tempclf.predict(X_test), y_test) / 5.\n",
    "    \n",
    "print tempresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LambdaMART из XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Необходимые технические строки. Исполняйте их в случае ошибки WindowsError Error 127. \n",
    "# Путь заменить на своё расположение mingw-64\n",
    "dir = r'C:\\Program Files\\mingw-w64\\x86_64-6.2.0-posix-seh-rt_v5-rev1\\mingw64\\bin'\n",
    "import os\n",
    "\n",
    "os.environ['PATH'].find(dir)\n",
    "os.environ['PATH'] = dir + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.147214344763\n",
      "0.410943681227\n"
     ]
    }
   ],
   "source": [
    "clf_temp = xgb.XGBClassifier(objective='rank:ndcg')\n",
    "clf_temp.fit(X_train, y_train)\n",
    "print ndcgl(clf_temp.predict(X_test), y_test, q_test)\n",
    "print ndcgl(clf_temp.predict(X_train), y_train, q_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.434840804088\n"
     ]
    }
   ],
   "source": [
    "tempresult = 0.\n",
    "\n",
    "for k in xrange(5):\n",
    "    shuffle_idx = np.random.permutation(num_elems)\n",
    "    X_train = X[shuffle_idx][:num_elems/2.]\n",
    "    X_valid = X[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    X_test = X[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "    y_train = y[shuffle_idx][:num_elems/2.]\n",
    "    y_valid = y[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "    y_test = y[shuffle_idx][num_elems*3./4.:]\n",
    "    \n",
    "    X_full_train = np.append(X_train, X_valid, axis=0)\n",
    "    y_full_train = np.append(y_train, y_valid)\n",
    "    \n",
    "    clf = xgb.XGBClassifier(objective='rank:ndcg')\n",
    "    clf.fit(X_full_train,y_full_train)\n",
    "    tempresult += ndcgl(clf.predict(X_test), y_test) / 5.\n",
    "    \n",
    "print tempresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа на 4000 элементах, 70 итераций бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 0\n",
      "Iteration # 1\n",
      "Iteration # 2\n",
      "Iteration # 3\n",
      "Iteration # 4\n",
      "Iteration # 5\n",
      "Iteration # 6\n",
      "Iteration # 7\n",
      "Iteration # 8\n",
      "Iteration # 9\n",
      "Iteration # 10\n",
      "Iteration # 11\n",
      "Iteration # 12\n",
      "Iteration # 13\n",
      "Iteration # 14\n",
      "Iteration # 15\n",
      "Iteration # 16\n",
      "Iteration # 17\n",
      "Iteration # 18\n",
      "Iteration # 19\n",
      "Iteration # 20\n",
      "Iteration # 21\n",
      "Iteration # 22\n",
      "Iteration # 23\n",
      "Iteration # 24\n",
      "Iteration # 25\n",
      "Iteration # 26\n",
      "Iteration # 27\n",
      "Iteration # 28\n",
      "Iteration # 29\n",
      "Iteration # 30\n",
      "Iteration # 31\n",
      "Iteration # 32\n",
      "Iteration # 33\n",
      "Iteration # 34\n",
      "Iteration # 35\n",
      "Iteration # 36\n",
      "Iteration # 37\n",
      "Iteration # 38\n",
      "Iteration # 39\n",
      "Iteration # 40\n",
      "Iteration # 41\n",
      "Iteration # 42\n",
      "Iteration # 43\n",
      "Iteration # 44\n",
      "Iteration # 45\n",
      "Iteration # 46\n",
      "Iteration # 47\n",
      "Iteration # 48\n",
      "Iteration # 49\n",
      "Iteration # 50\n",
      "Iteration # 51\n",
      "Iteration # 52\n",
      "Iteration # 53\n",
      "Iteration # 54\n",
      "Iteration # 55\n",
      "Iteration # 56\n",
      "Iteration # 57\n",
      "Iteration # 58\n",
      "Iteration # 59\n",
      "Iteration # 60\n",
      "Iteration # 61\n",
      "Iteration # 62\n",
      "Iteration # 63\n",
      "Iteration # 64\n",
      "Iteration # 65\n",
      "Iteration # 66\n",
      "Iteration # 67\n",
      "Iteration # 68\n",
      "Iteration # 69\n",
      "Wall time: 3h 41min 39s\n"
     ]
    }
   ],
   "source": [
    "shuffle_idx = np.random.permutation(num_elems)\n",
    "X_train = X[shuffle_idx][:num_elems/2.]\n",
    "X_valid = X[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "X_test = X[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "y_train = y[shuffle_idx][:num_elems/2.]\n",
    "y_valid = y[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "y_test = y[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "q_train = queries[shuffle_idx][:num_elems/2.]\n",
    "q_valid = queries[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "q_test = queries[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "queries_train = q[shuffle_idx][:num_elems/2.]\n",
    "queries_valid = q[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "queries_test = q[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "X_full_train = np.append(X_train, X_valid, axis=0)\n",
    "y_full_train = np.append(y_train, y_valid)\n",
    "q_full_train = np.append(q_train, q_valid)\n",
    "queries_full_train = np.append(queries_train, queries_valid, axis=0)\n",
    "\n",
    "%time clf_big = LambdaMART(70, alpha=0.5, beta=1., ).fit(X_full_train, y_full_train, q_full_train, queries_full_train)\n",
    "#y_pred1 = clf1.predict(X_test, q_test, queries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896477581668\n"
     ]
    }
   ],
   "source": [
    "y_pred_big = clf_big.predict(X_test, q_test, queries_test)\n",
    "print ndcgl(y_pred_big, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.733113475428\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "clf = xgb.XGBClassifier(objective='rank:ndcg')\n",
    "clf.fit(X_full_train,y_full_train)\n",
    "print ndcgl(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Проверка случайного выбора фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Without subset 0.589559508361\n",
      "With subset 0.525202845018\n",
      "Stochastic 0.465555208682\n",
      "40\n",
      "Without subset 0.670012899467\n",
      "With subset 0.851643743565\n",
      "Stochastic 0.79434887815\n",
      "70\n",
      "Without subset 0.595825485951\n",
      "With subset 0.837945450273\n",
      "Stochastic 0.732566107838\n",
      "100\n",
      "Without subset 0.625597894605\n",
      "With subset 0.805930029937\n",
      "Stochastic 0.621950881675\n",
      "130\n",
      "Without subset 0.635118472228\n",
      "With subset 0.838777861945\n",
      "Stochastic 0.646343802709\n",
      "160\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ea5e83d9c0ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mclf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambdaMART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries_full_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mclf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambdaMART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries_full_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mclf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambdaMART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m                       \u001b[0mstochastic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries_full_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6943b8d58004>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, qids_train, queries_train, verbose)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mqueries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueries_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Grad:\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6943b8d58004>\u001b[0m in \u001b[0;36mloss_grad\u001b[1;34m(self, pred_y, y, id_y)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_elems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                 \u001b[0mdelta_ndcg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndcg_replace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                     \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6943b8d58004>\u001b[0m in \u001b[0;36mndcg_replace\u001b[1;34m(self, value_a, value_b, id_a, id_b)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mndcg_replace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2.\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mvalue_b\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2.\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mvalue_a\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mid_a\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mid_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shuffle_idx = np.random.permutation(num_elems)\n",
    "X_train = X[shuffle_idx][:num_elems/2.]\n",
    "X_valid = X[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "X_test = X[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "y_train = y[shuffle_idx][:num_elems/2.]\n",
    "y_valid = y[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "y_test = y[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "q_train = queries[shuffle_idx][:num_elems/2.]\n",
    "q_valid = queries[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "q_test = queries[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "queries_train = q[shuffle_idx][:num_elems/2.]\n",
    "queries_valid = q[shuffle_idx][num_elems/2.:num_elems*3./4.]\n",
    "queries_test = q[shuffle_idx][num_elems*3./4.:]\n",
    "\n",
    "X_full_train = np.append(X_train, X_valid, axis=0)\n",
    "y_full_train = np.append(y_train, y_valid)\n",
    "q_full_train = np.append(q_train, q_valid)\n",
    "queries_full_train = np.append(queries_train, queries_valid, axis=0)\n",
    "\n",
    "results = []\n",
    "\n",
    "for n in xrange(10, 600, 30):\n",
    "    print n\n",
    "\n",
    "    clf1 = LambdaMART(n, alpha=0.5, beta=1.).fit(X_full_train, y_full_train, q_full_train, queries_full_train)\n",
    "    clf2 = LambdaMART(n, alpha=0.5, beta=1., feature_subset=True, feature_fraction=0.3).fit(X_full_train, y_full_train, q_full_train, queries_full_train)\n",
    "    clf3 = LambdaMART(n, alpha=0.5, beta=1., feature_subset=True, feature_fraction=0.3, \\\n",
    "                      stochastic=True).fit(X_full_train, y_full_train, q_full_train, queries_full_train)\n",
    "    \n",
    "    result1 = ndcgl(clf1.predict(X_test, q_test, queries_test), y_test)\n",
    "    result2 = ndcgl(clf2.predict(X_test, q_test, queries_test), y_test)\n",
    "    result3 = ndcgl(clf3.predict(X_test, q_test, queries_test), y_test)\n",
    "    results.append((result1, result2, result3))\n",
    "    \n",
    "    print \"Without subset\", result1\n",
    "    print \"With subset\", result2\n",
    "    print \"Stochastic\", result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.619296498687\n",
      "0.446995121205\n"
     ]
    }
   ],
   "source": [
    "print ndcgl(clf1.predict(X_test, q_test, queries_test), y_test)\n",
    "print ndcgl(clf2.predict(X_test, q_test, queries_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.58955950836136284, 0.52520284501832992, 0.46555520868212591),\n",
       " (0.67001289946652387, 0.85164374356483075, 0.79434887815035293),\n",
       " (0.59582548595062079, 0.83794545027274325, 0.73256610783800979),\n",
       " (0.62559789460458759, 0.80593002993736984, 0.6219508816753645),\n",
       " (0.63511847222811579, 0.83877786194521575, 0.64634380270875258)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
