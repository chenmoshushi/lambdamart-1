{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LambdaMART:\n",
    "    def __init__(self, n_estimators, base_estimator=DecisionTreeRegressor(), step_estimator=DecisionTreeRegressor(),\n",
    "                 alpha=1., beta=1.):\n",
    "        \"\"\"\n",
    "            n_estimators : число деревьев в обучении\n",
    "            base_estimator : выбор модели для каждой итерации\n",
    "            step_estimator : выбор модели для предсказания темпа обучения\n",
    "            alpha : коэффициент регуляризации XGBoost\n",
    "            beta : коэффициент при предсказании темпа обучения\n",
    "        \"\"\"\n",
    "        self.estimators = []\n",
    "        self.step_estimators = []\n",
    "        self.n_estimators = n_estimators\n",
    "        self.base_estimator = base_estimator\n",
    "        self.step_estimator = step_estimator\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        #self.q_dict = defaultdict(lambda : np.zeros(query_d))\n",
    "        #self.query_d = query_d\n",
    "        \n",
    "    def fit(self, X, y, qids, queries, verbose=False):\n",
    "        \"\"\"\n",
    "            X : признаки пар запрос-документ\n",
    "            y : метки релевантности\n",
    "            qids : id запросов\n",
    "            queries : признаки запросов\n",
    "        \"\"\"\n",
    "        self.estimators = []\n",
    "        self.step_estimators = []\n",
    "        for i in xrange(self.n_estimators):\n",
    "            grad = self.loss_grad(self.predict(X), y)\n",
    "            h = self.double_grad(self.predict(X), y)\n",
    "            if verbose:\n",
    "                print \"Grad:\"\n",
    "                print grad\n",
    "            estimator = deepcopy(self.base_estimator)\n",
    "            estimator.fit(X, -grad/ (self.alpha + h))\n",
    "            self.estimators.append(estimator)\n",
    "            if verbose:\n",
    "                print \"Predict:\"\n",
    "                print self.predict(X)\n",
    "            # Обучим предсказатель шага\n",
    "            #q_dict = self.generate_query_features(X, qids)\n",
    "            step_estimator = deepcopy(self.step_estimator)\n",
    "            # Список всех запросов(уникальных)\n",
    "            qs = np.unique(qids)\n",
    "            # Список значений того, что нужно предсказывать\n",
    "            pred_values = np.zeros(len(qs))\n",
    "            q_list = np.zeros((len(qs), queries.shape[1]))\n",
    "            for idx, q in enumerate(qs):\n",
    "                # Суммируем значения по всем элементам с данным запросом q\n",
    "                pred_values[idx] = 0.\n",
    "                for j in xrange(X.shape[0]):\n",
    "                    if qid == q:\n",
    "                        q_list[idx] = queries[j]\n",
    "                        pred_values[idx] += 1. / (1. + self.beta * h[j])            \n",
    "                #q_list[idx] = q_dict[q]\n",
    "            step_estimator.fit(q_list, pred_values)\n",
    "            self.step_estimators.append(step_estimator)\n",
    "        return self\n",
    "    \n",
    "    \"\"\"def generate_query_features(X, qids):\n",
    "        q_dict = defaultdict(lambda : np.zeros(query_d))\n",
    "        unique_q, counts = np.unique(queries, return_counts=True)\n",
    "        for i,q in enumerate(unique_q):\n",
    "            for j in xrange(X.shape[0]):\n",
    "                if queries[j] == q:\n",
    "                    q_dict[q] += np.append(X[j][0:5], X[j][10:15]) / counts[i]\n",
    "        return q_dict\"\"\"\n",
    "            \n",
    "    def predict(self, X, qids, queries, verbose=False):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for est_i in xrange(self.n_estimators):\n",
    "            est_result = self.n_estimators[est_i].predict(X)\n",
    "            step = self.step_estimators[est_i].predict(queries)\n",
    "            for i in xrange(X.shape[0]):\n",
    "                y_pred[i] += est_result[i] * step\n",
    "        return y_pred\n",
    "    \n",
    "    def loss_grad(self, pred_y, y):\n",
    "        n_elems = y.shape[0]\n",
    "        grad = np.zeros(n_elems)\n",
    "        # id_y - индексы в массиве pred_y, отсортированные по убыванию ранжирующей функции \n",
    "        id_y = np.argsort(np.argsort(y)[::-1])\n",
    "        for i in xrange(n_elems):\n",
    "            for j in xrange(n_elems):\n",
    "                buf = 0.\n",
    "                if y[i] > y[j]:\n",
    "                    buf = -self.rho(pred_y[i], pred_y[j])\n",
    "                if y[i] < y[j]:\n",
    "                    buf = self.rho(pred_y[j], pred_y[i])\n",
    "                if buf != 0.:\n",
    "                    grad[i] += np.abs(self.ndcg_replace(y[i], y[j], id_y[i], id_y[j])) * buf\n",
    "        return grad\n",
    "        \n",
    "    def double_grad(self, pred_y, y):\n",
    "        n_elems = y.shape[0]\n",
    "        h = np.zeros(n_elems)\n",
    "        # id_y - индексы в массиве pred_y, отсортированные по убыванию ранжирующей функции \n",
    "        id_y = np.argsort(np.argsort(y)[::-1])\n",
    "        for i in xrange(n_elems):\n",
    "            for j in xrange(n_elems):\n",
    "                delta_ndcg = np.abs(self.ndcg_replace(y[i], y[j], id_y[i], id_y[j]))\n",
    "                h[i] += delta_ndcg * self.rho(pred_y[i], pred_y[j]) * (1 - self.rho(pred_y[i], pred_y[j]))\n",
    "        return h\n",
    "                \n",
    "    def ndcg_replace(self, value_a, value_b, id_a, id_b):\n",
    "        return (2. ** value_b - 2. ** value_a) * (1./ np.log2(2 + id_a) - 1./ np.log2(2 + id_b))\n",
    "    \n",
    "    def rho(self, a, b):\n",
    "        return 1. / (1. + np.exp(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.2,  0.4,  0.6,  0.8,  1. ,  1.2,  1.4,  1.6,  1.8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0., 2., 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее рассмотрим работу на стандартном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример получения индексов элементов в отсортированном в массиве отсортированном по убыванию. Нужно для вычисления метрик\n",
    "a = [2,3,4,1]\n",
    "\n",
    "def do_magic(a):\n",
    "    return np.argsort(np.argsort(a)[::-1])\n",
    "\n",
    "do_magic(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем часть датасета MQ2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Проверка на части датасета MQ2007\n",
    "fin = open('train.txt', 'r')\n",
    "\n",
    "num_elems = 200\n",
    "X = np.zeros((num_elems, 46))\n",
    "y = np.zeros(num_elems)\n",
    "queries = np.zeros(num_elems)\n",
    "\n",
    "num = 0\n",
    "i = 0\n",
    "\n",
    "lines = fin.readlines()[:num_elems]\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    parsed = line.split(' ')\n",
    "    y[i] = int(parsed[0])\n",
    "    queries[i] = int(parsed[1][4:])\n",
    "    for j in xrange(46):\n",
    "        if j < 9:\n",
    "            X[i][j] = float(parsed[j + 2][2:])\n",
    "        else:\n",
    "            X[i][j] = float(parsed[j + 2][3:])\n",
    "                \n",
    "# Нормализуем y\n",
    "y /= np.max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Признаки для запросов\n",
    "query_d = 10 # Число признаков в запросе. Берём 0-4, 10-14 признаки пары и усредняем\n",
    "q_dict = defaultdict(lambda : np.zeros(query_d)) # dictionary, который по id запроса возвращает его признаки\n",
    "\n",
    "unique_q, counts = np.unique(queries, return_counts=True)\n",
    "for i,q in enumerate(unique_q):\n",
    "    for j in xrange(X.shape[0]):\n",
    "        if queries[j] == q:\n",
    "            q_dict[q] += np.append(X[j][0:5], X[j][10:15]) / counts[i]\n",
    "\n",
    "# Финальная матрица для запросов. По индексу получаем признаки запроса, соответствующие элементу из X с этим индексом\n",
    "q = np.zeros((num_elems, query_d))\n",
    "for i in xrange(num_elems):\n",
    "    q[i] = q_dict[queries[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09802615,  0.13750005,  0.18125   , ...,  0.18866905,\n",
       "         0.15317262,  0.07571875],\n",
       "       [ 0.09802615,  0.13750005,  0.18125   , ...,  0.18866905,\n",
       "         0.15317262,  0.07571875],\n",
       "       [ 0.09802615,  0.13750005,  0.18125   , ...,  0.18866905,\n",
       "         0.15317262,  0.07571875],\n",
       "       ..., \n",
       "       [ 0.05055205,  0.025     ,  0.1       , ...,  0.1       ,\n",
       "         0.025     ,  0.04307292],\n",
       "       [ 0.05055205,  0.025     ,  0.1       , ...,  0.1       ,\n",
       "         0.025     ,  0.04307292],\n",
       "       [ 0.05055205,  0.025     ,  0.1       , ...,  0.1       ,\n",
       "         0.025     ,  0.04307292]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Разобьём выборку на train, validation, test\n",
    "shuffle_idx = np.random.permutation(num_elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X[shuffle_idx][:100]\n",
    "X_valid = X[shuffle_idx][100:150]\n",
    "X_test = X[shuffle_idx][150:200]\n",
    "\n",
    "y_train = y[shuffle_idx][:100]\n",
    "y_valid = y[shuffle_idx][100:150]\n",
    "y_test = y[shuffle_idx][150:200]\n",
    "\n",
    "q_train = queries[shuffle_idx][:100]\n",
    "q_valid = queries[shuffle_idx][100:150]\n",
    "q_test = queries[shuffle_idx][150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ndcgl(y_pred, y, L=10):\n",
    "    \"\"\"\n",
    "        y_pred : предсказанные значения функции ранжирования\n",
    "        y : метки релевантности\n",
    "    \"\"\"\n",
    "    dcgl = 0.\n",
    "    idcgl = 0.\n",
    "    # Отсортируем значения по убыванию функции ранжирования\n",
    "    idx = np.argsort(y_pred)[::-1]\n",
    "    # Метки релевантности для отсортированного массива y_pred\n",
    "    l = y[idx]\n",
    "    for i in xrange(L):\n",
    "        dcgl += (2. ** l[i] - 1) / np.log2(i + 2)\n",
    "        idcgl += 1 / np.log2(i + 2)\n",
    "    return dcgl / idcgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1 0.211887805341\n",
      "0.1 2 0.22071794876\n",
      "0.1 5 0.416157258976\n",
      "0.1 7 0.342168816644\n",
      "0.1 10 0.342939054669\n",
      "0.1 20 0.505389034784\n",
      "0.5 1 0.530775041421\n",
      "0.5 2 0.497394644788\n",
      "0.5 5 0.318533164469\n",
      "0.5 7 0.352536470777\n",
      "0.5 10 0.434677945375\n",
      "0.5 20 0.453780324519\n",
      "1.0 1 0.369109617977\n",
      "1.0 2 0.4712324459\n",
      "1.0 5 0.47251167022\n",
      "1.0 7 0.498465859973\n",
      "1.0 10 0.462876329244\n",
      "1.0 20 0.387205454472\n",
      "2.0 1 0.441542208886\n",
      "2.0 2 0.45065075968\n",
      "2.0 5 0.527608142565\n",
      "2.0 7 0.541846304858\n",
      "2.0 10 0.491570470471\n",
      "2.0 20 0.312225088744\n",
      "5.0 1 0.449811609374\n",
      "5.0 2 0.451307802016\n",
      "5.0 5 0.470528237462\n",
      "5.0 7 0.473860480277\n",
      "5.0 10 0.4835748785\n",
      "5.0 20 0.354967777456\n",
      "Max at:  (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Небольшой GridSearch.\n",
    "from numpy import unravel_index\n",
    "\n",
    "arr_a = [0.1, 0.5, 1., 2.,5.]\n",
    "arr_L = [1, 2, 5, 7, 10, 20]\n",
    "\n",
    "results = np.zeros((len(arr_a), len(arr_L)))\n",
    "\n",
    "for i_a, a in enumerate(arr_a):\n",
    "    for i_L, L in enumerate(arr_L):\n",
    "        clf = LambdaMART(L, alpha=a).fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        results[i_a, i_L] = ndcgl(y_pred, y_test)\n",
    "        print a, L, ndcgl(y_pred, y_test)\n",
    "        \n",
    "print \"Max at: \", unravel_index(np.argmax(results), results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 7, 0.54184630485795415)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_a[3], arr_L[3], results[3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 4, 3, 1]), array([0, 3, 2, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,5,3,4])\n",
    "b = np.array([1,0,2,3])\n",
    "idx = np.argsort(a)[::-1]\n",
    "a[idx], b[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41854413705574878"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обычный DecisionTreeRegressor\n",
    "tempclf = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "ndcgl(tempclf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LambdaMART из XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Необходимые технические строки. Исполняйте их в случае ошибки WindowsError Error 127. \n",
    "# Путь заменить на своё расположение mingw-64\n",
    "dir = r'C:\\Program Files\\mingw-w64\\x86_64-6.2.0-posix-seh-rt_v5-rev1\\mingw64\\bin'\n",
    "import os\n",
    "\n",
    "os.environ['PATH'].find(dir)\n",
    "os.environ['PATH'] = dir + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Проверка на части датасета MQ2007\n",
    "fin = open('train.txt', 'r')\n",
    "\n",
    "num_elems = 1000\n",
    "X = np.zeros((num_elems, 46))\n",
    "y = np.zeros(num_elems)\n",
    "\n",
    "num = 0\n",
    "i = 0\n",
    "\n",
    "lines = fin.readlines()[:num_elems]\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    parsed = line.split(' ')\n",
    "    # qid\n",
    "    y[i] = int(parsed[0])\n",
    "    for j in xrange(46):\n",
    "        if j < 9:\n",
    "            X[i][j] = float(parsed[j + 2][2:])\n",
    "        else:\n",
    "            X[i][j] = float(parsed[j + 2][3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(objective='rank:ndcg')\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83333333333333337"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
